{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PlantDisease_tutorial.ipynb ",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/totti0223/deep_learning_for_biologists_with_keras/blob/master/notebooks/PlantDisease_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGkuR5rue-wg",
        "colab_type": "text"
      },
      "source": [
        "# Training a Plant Disease Diagnosis Model with PlantVillage Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DbSbnYUnOvy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from skimage.io import imread\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn .model_selection import train_test_split\n",
        "\n",
        "\n",
        "import keras\n",
        "import keras.backend as K\n",
        "from keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras import layers\n",
        "from keras.models import Sequential, Model\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g426U4uPiRHp",
        "colab_type": "text"
      },
      "source": [
        "# Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSN_txlHfJNU",
        "colab_type": "text"
      },
      "source": [
        "## Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4jjTgsFe4q8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get install subversion > /dev/null\n",
        "\n",
        "#Retreive specifc diseases of tomato for training\n",
        "!svn export https://github.com/spMohanty/PlantVillage-Dataset/trunk/raw/color/Tomato___Bacterial_spot image/Tomato___Bacterial_spot　>  /dev/null\n",
        "!svn export https://github.com/spMohanty/PlantVillage-Dataset/trunk/raw/color/Tomato___Early_blight image/Tomato___Early_blight　>  /dev/null\n",
        "!svn export https://github.com/spMohanty/PlantVillage-Dataset/trunk/raw/color/Tomato___Late_blight image/Tomato___Late_blight　>  /dev/null\n",
        "!svn export https://github.com/spMohanty/PlantVillage-Dataset/trunk/raw/color/Tomato___Septoria_leaf_spot image/Tomato___Septoria_leaf_spot　>  /dev/null\n",
        "!svn export https://github.com/spMohanty/PlantVillage-Dataset/trunk/raw/color/Tomato___Target_Spot image/Tomato___Target_Spot　>  /dev/null\n",
        "!svn export https://github.com/spMohanty/PlantVillage-Dataset/trunk/raw/color/Tomato___healthy image/Tomato___healthy　>  /dev/null"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNhZKWt5jeJV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#folder structure\n",
        "!ls image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_Zv9KQT6hxr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(15,10))\n",
        "\n",
        "#visualize several images\n",
        "\n",
        "parent_directory = \"image\"\n",
        "\n",
        "for i, folder in enumerate(os.listdir(parent_directory)):\n",
        "    print(folder)\n",
        "    folder_directory = os.path.join(parent_directory,folder)\n",
        "    files = os.listdir(folder_directory)\n",
        "    #will inspect only 1 image per folder\n",
        "    file = files[0] \n",
        "    file_path = os.path.join(folder_directory,file)\n",
        "    \n",
        "    image = imread(file_path)\n",
        "    plt.subplot(1,6,i+1)\n",
        "    plt.imshow(image)\n",
        "    plt.axis(\"off\")\n",
        "    \n",
        "    name = folder.split(\"___\")[1][:-1]\n",
        "    plt.title(name)\n",
        "    #plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4w9gq1DAEUq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load everything into memory\n",
        "x = []\n",
        "y = []\n",
        "class_names = []\n",
        "parent_directory = \"image\"\n",
        "\n",
        "for i,folder in enumerate(os.listdir(parent_directory)):\n",
        "    print(i,folder)\n",
        "    class_names.append(folder)\n",
        "    folder_directory = os.path.join(parent_directory,folder)\n",
        "    files = os.listdir(folder_directory)\n",
        "    #will inspect only 1 image per folder\n",
        "    for file in files:\n",
        "        file_path = os.path.join(folder_directory,file)\n",
        "        image = load_img(file_path,target_size=(64,64))\n",
        "        image = img_to_array(image)/255.\n",
        "        x.append(image)\n",
        "        y.append(i)\n",
        "\n",
        "x = np.array(x)\n",
        "y = to_categorical(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6ZshzbdBiMl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#check the data shape\n",
        "print(x.shape)\n",
        "print(y.shape)\n",
        "print(y[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cJXZ4agBtT-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, _x, y_train, _y = train_test_split(x,y,test_size=0.2, stratify = y, random_state = 1)\n",
        "x_valid,x_test, y_valid, y_test = train_test_split(_x,_y,test_size=0.4, stratify = _y, random_state = 1)\n",
        "\n",
        "print(\"train data:\",x_train.shape,y_train.shape)\n",
        "print(\"validation data:\",x_valid.shape,y_valid.shape)\n",
        "print(\"test data:\",x_test.shape,y_test.shape)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ma87VMOBoX-k",
        "colab_type": "text"
      },
      "source": [
        "## Model Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kncFFJtljmbh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "K.clear_session()\n",
        "\n",
        "nfilter = 32\n",
        "\n",
        "\n",
        "#VGG16 like model\n",
        "model = Sequential([\n",
        "    #block1\n",
        "    layers.Conv2D(nfilter,(3,3),padding=\"same\",name=\"block1_conv1\",input_shape=(64,64,3)),\n",
        "    layers.Activation(\"relu\"),\n",
        "    layers.BatchNormalization(),\n",
        "    #layers.Dropout(rate=0.2),   \n",
        "    \n",
        "    layers.Conv2D(nfilter,(3,3),padding=\"same\",name=\"block1_conv2\"),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation(\"relu\"),\n",
        "    #layers.Dropout(rate=0.2),\n",
        "    layers.MaxPooling2D((2,2),strides=(2,2),name=\"block1_pool\"),\n",
        "    \n",
        "    #block2\n",
        "    layers.Conv2D(nfilter*2,(3,3),padding=\"same\",name=\"block2_conv1\"),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation(\"relu\"),\n",
        "    #layers.Dropout(rate=0.2),\n",
        "    \n",
        "    layers.Conv2D(nfilter*2,(3,3),padding=\"same\",name=\"block2_conv2\"),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation(\"relu\"),\n",
        "    #layers.Dropout(rate=0.2),\n",
        "    layers.MaxPooling2D((2,2),strides=(2,2),name=\"block2_pool\"),\n",
        "    \n",
        "    #block3\n",
        "    layers.Conv2D(nfilter*2,(3,3),padding=\"same\",name=\"block3_conv1\"),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation(\"relu\"),\n",
        "    #layers.Dropout(rate=0.2),\n",
        "    \n",
        "    layers.Conv2D(nfilter*4,(3,3),padding=\"same\",name=\"block3_conv2\"),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation(\"relu\"),\n",
        "    #layers.Dropout(rate=0.2),\n",
        "    \n",
        "    layers.Conv2D(nfilter*4,(3,3),padding=\"same\",name=\"block3_conv3\"),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation(\"relu\"),\n",
        "    #layers.Dropout(rate=0.2),\n",
        "    layers.MaxPooling2D((2,2),strides=(2,2),name=\"block3_pool\"),\n",
        "    #layers.Flatten(),\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    \n",
        "    #inference layer\n",
        "    layers.Dense(128,name=\"fc1\"),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation(\"relu\"),\n",
        "    #layers.Dropout(rate=0.2),\n",
        "    \n",
        "    layers.Dense(128,name=\"fc2\"),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation(\"relu\"),    \n",
        "    #layers.Dropout(rate=0.2),\n",
        "    \n",
        "    layers.Dense(6,name=\"prepredictions\"),\n",
        "    layers.Activation(\"softmax\",name=\"predictions\")\n",
        "    \n",
        "])\n",
        "\n",
        "model.compile(optimizer = \"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMqZzhiztiv0",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bxsVtqBFmoH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#utilize early stopping function to stop at the lowest validation loss\n",
        "es = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='auto')\n",
        "#utilize save best weight model during training\n",
        "ckpt = ModelCheckpoint(\"PlantDiseaseCNNmodel.hdf5\", monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BEzeqUZofYP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#we will define a generator class for training data and validation data seperately, as no augmentation is not required for validation data\n",
        "t_gen = ImageDataGenerator(rotation_range=90,horizontal_flip=True)\n",
        "v_gen = ImageDataGenerator()\n",
        "train_gen = t_gen.flow(x_train,y_train,batch_size=98)\n",
        "valid_gen = v_gen.flow(x_valid,y_valid,batch_size=98)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eglAa6dhGoc9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit_generator(\n",
        "    train_gen,\n",
        "    steps_per_epoch = train_gen.n // 98,\n",
        "    callbacks = [es,ckpt], \n",
        "    validation_data = valid_gen,\n",
        "    validation_steps = valid_gen.n // 98,\n",
        "    \n",
        "    epochs=50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f481o6lhQDtm",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMivaFVWubGk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load the model weight file with lowest validation loss\n",
        "model.load_weights(\"PlantDiseaseCNNmodel.hdf5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euZDPvxwWTNG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#or can obtain the pretrained model from the github repo."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhxE8TK0Mvrx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#check the model metrics\n",
        "print(model.metrics_names)\n",
        "#evaluate training data\n",
        "print(model.evaluate(x= x_train, y = y_train))\n",
        "#evaluate  validation data\n",
        "print(model.evaluate(x= x_valid, y = y_valid))\n",
        "#evaluate  test data\n",
        "print(model.evaluate(x= x_test, y = y_test))      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLkicY6kMyC7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#draw a confusion matrix\n",
        "\n",
        "#true label\n",
        "y_true = np.argmax(y_test,axis=1)\n",
        "\n",
        "#prediction label\n",
        "Y_pred = model.predict(x_test)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "\n",
        "print(y_true)\n",
        "print(y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zj76uI3vy_xJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, classes,\n",
        "                          normalize=False,\n",
        "                          title=None,\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if not title:\n",
        "        if normalize:\n",
        "            title = 'Normalized confusion matrix'\n",
        "        else:\n",
        "            title = 'Confusion matrix, without normalization'\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    # Only use the labels that appear in the data\n",
        "    #classes = classes[unique_labels(y_true, y_pred)]\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(5,5))\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    #ax.figure.colorbar(im, ax=ax)\n",
        "    # We want to show all ticks...\n",
        "    ax.set(xticks=np.arange(cm.shape[1]),\n",
        "           yticks=np.arange(cm.shape[0]),\n",
        "           # ... and label them with the respective list entries\n",
        "           xticklabels=classes, yticklabels=classes,\n",
        "           title=title,\n",
        "           ylabel='True label',\n",
        "           xlabel='Predicted label')\n",
        "\n",
        "    # Rotate the tick labels and set their alignment.\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "             rotation_mode=\"anchor\")\n",
        "\n",
        "    # Loop over data dimensions and create text annotations.\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            ax.text(j, i, format(cm[i, j], fmt),\n",
        "                    ha=\"center\", va=\"center\",\n",
        "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    fig.tight_layout()\n",
        "    return ax\n",
        "\n",
        "\n",
        "np.set_printoptions(precision=2)\n",
        "\n",
        "plot_confusion_matrix(y_true, y_pred, classes=class_names, normalize=True,\n",
        "                      title='Normalized confusion matrix')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dcn7_dqA2wbA",
        "colab_type": "text"
      },
      "source": [
        "## Predicting Indivisual Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xv4N5Zvw2zUD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n = 15 #do not exceed (number of test image - 1)\n",
        "\n",
        "plt.imshow(x_test[n])\n",
        "plt.show()\n",
        "\n",
        "true_label = np.argmax(y_test,axis=1)[n]\n",
        "print(\"true_label is:\",true_label,\":\",class_names[true_label])\n",
        "prediction = model.predict(x_test[n][np.newaxis,...])[0]\n",
        "print(\"predicted_value is:\",prediction)\n",
        "predicted_label = np.argmax(prediction)\n",
        "print(\"predicted_label is:\",predicted_label,\":\",class_names[predicted_label])\n",
        "\n",
        "if true_label == predicted_label:\n",
        "    print(\"correct prediction\")\n",
        "else:\n",
        "    print(\"wrong prediction\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}