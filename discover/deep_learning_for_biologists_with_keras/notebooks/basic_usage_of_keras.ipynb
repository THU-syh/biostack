{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "basic_usage_of_keras.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/totti0223/deep_learning_for_biologists_with_keras/blob/master/notebooks/basic_usage_of_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "jP2Bu5lEplk-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Basic Codes to train and run CNN model in Keras\n",
        "- for clarity, the library import commands will be redundant throughout the notebook"
      ]
    },
    {
      "metadata": {
        "id": "_71Osx0Vj4T1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Notebook and data preparation "
      ]
    },
    {
      "metadata": {
        "id": "iHJBi2eGqUTx",
        "colab_type": "code",
        "outputId": "24961de9-429d-4e11-c4b5-efe1eff00db7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "cell_type": "code",
      "source": [
        "#we will use the rice seed image datset as an example\n",
        "!apt-get install subversion > /dev/null\n",
        "!svn export https://github.com/totti0223/deep_learning_for_biologists_with_keras/trunk/notebooks/data/image image > /dev/null\n",
        "    \n",
        "#to make sure keras imagedatagenerator flow from dataframe works\n",
        "!pip uninstall keras-preprocessing -y > /dev/null\n",
        "!pip install git+https://github.com/keras-team/keras-preprocessing.git > /dev/null"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "svn: E155000: Destination directory exists; please remove the directory or use --force to overwrite\n",
            "svn: E155000: 'image' already exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "y9ClH2zSv40S",
        "colab_type": "code",
        "outputId": "5612d56d-b328-4217-f495-0555ce7d89fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        }
      },
      "cell_type": "code",
      "source": [
        "#check the directory structure\n",
        "import os\n",
        "\n",
        "for dirpath, dirnames, filenames, in os.walk(\"image\"):\n",
        "    print(dirpath)\n",
        "    if dirnames:\n",
        "        print(dirnames)\n",
        "    if filenames:\n",
        "        print(filenames)\n",
        "    print(\"__________\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "image\n",
            "['train', 'test']\n",
            "['train.txt', 'test.txt']\n",
            "__________\n",
            "image/train\n",
            "['proper', 'broken']\n",
            "__________\n",
            "image/train/proper\n",
            "['37.jpg', '66.jpg', '87.jpg', '117.jpg', '99.jpg', '31.jpg', '60.jpg', '116.jpg', '57.jpg', '77.jpg', '134.jpg', '73.jpg', '200.jpg', '183.jpg', '17.jpg', '80.jpg', '55.jpg', '72.jpg', '24.jpg', '38.jpg', '111.jpg', '41.jpg', '192.jpg', '151.jpg', '29.jpg', '32.jpg', '113.jpg', '50.jpg', '132.jpg', '94.jpg', '140.jpg', '154.jpg', '54.jpg', '108.jpg', '95.jpg', '153.jpg', '20.jpg', '21.jpg', '42.jpg', '51.jpg', '89.jpg', '84.jpg', '30.jpg', '104.jpg', '198.jpg', '19.jpg', '112.jpg', '12.jpg', '115.jpg', '107.jpg', '27.jpg', '23.jpg', '131.jpg', '90.jpg', '138.jpg', '85.jpg', '34.jpg', '102.jpg', '67.jpg', '76.jpg', '18.jpg', '82.jpg', '40.jpg', '35.jpg', '74.jpg', '49.jpg', '197.jpg', '22.jpg', '58.jpg', '14.jpg', '79.jpg', '127.jpg', '96.jpg', '39.jpg', '106.jpg', '136.jpg', '25.jpg', '93.jpg', '129.jpg', '28.jpg', '98.jpg', '16.jpg', '56.jpg', '118.jpg', '190.jpg', '81.jpg', '33.jpg', '105.jpg', '122.jpg', '193.jpg', '63.jpg', '78.jpg', '48.jpg', '36.jpg', '71.jpg', '88.jpg', '47.jpg', '53.jpg', '126.jpg', '120.jpg', '110.jpg', '121.jpg', '62.jpg', '100.jpg', '52.jpg', '83.jpg', '92.jpg', '124.jpg', '128.jpg', '59.jpg', '11.jpg', '114.jpg', '65.jpg', '187.jpg', '43.jpg', '133.jpg', '15.jpg', '61.jpg', '139.jpg', '143.jpg', '75.jpg', '46.jpg', '91.jpg', '97.jpg', '45.jpg', '64.jpg', '123.jpg', '103.jpg', '13.jpg', '181.jpg', '130.jpg', '109.jpg', '148.jpg', '149.jpg', '68.jpg', '70.jpg', '119.jpg', '86.jpg', '101.jpg', '.DS_Store', '26.jpg', '44.jpg', '188.jpg', '125.jpg', '69.jpg', '135.jpg', '137.jpg']\n",
            "__________\n",
            "image/train/broken\n",
            "['223.jpg', '233.jpg', '291.jpg', '229.jpg', '287.jpg', '262.jpg', '202.jpg', '394.jpg', '396.jpg', '361.jpg', '379.jpg', '264.jpg', '265.jpg', '317.jpg', '145.jpg', '168.jpg', '393.jpg', '366.jpg', '357.jpg', '303.jpg', '302.jpg', '312.jpg', '319.jpg', '284.jpg', '155.jpg', '360.jpg', '335.jpg', '214.jpg', '289.jpg', '282.jpg', '249.jpg', '295.jpg', '169.jpg', '207.jpg', '180.jpg', '310.jpg', '370.jpg', '365.jpg', '374.jpg', '205.jpg', '364.jpg', '296.jpg', '400.jpg', '280.jpg', '363.jpg', '257.jpg', '348.jpg', '373.jpg', '300.jpg', '217.jpg', '161.jpg', '333.jpg', '208.jpg', '263.jpg', '351.jpg', '251.jpg', '255.jpg', '171.jpg', '369.jpg', '160.jpg', '260.jpg', '186.jpg', '315.jpg', '309.jpg', '376.jpg', '306.jpg', '219.jpg', '292.jpg', '362.jpg', '395.jpg', '166.jpg', '380.jpg', '327.jpg', '252.jpg', '277.jpg', '293.jpg', '258.jpg', '382.jpg', '286.jpg', '352.jpg', '384.jpg', '259.jpg', '174.jpg', '271.jpg', '343.jpg', '256.jpg', '353.jpg', '344.jpg', '279.jpg', '375.jpg', '313.jpg', '182.jpg', '178.jpg', '288.jpg', '234.jpg', '173.jpg', '250.jpg', '179.jpg', '199.jpg', '299.jpg', '359.jpg', '325.jpg', '158.jpg', '278.jpg', '321.jpg', '391.jpg', '330.jpg', '283.jpg', '308.jpg', '334.jpg', '211.jpg', '175.jpg', '304.jpg', '228.jpg', '231.jpg', '201.jpg', '254.jpg', '318.jpg', '172.jpg', '147.jpg', '269.jpg', '220.jpg', '185.jpg', '152.jpg', '224.jpg', '387.jpg', '371.jpg', '164.jpg', '150.jpg', '347.jpg', '226.jpg', '345.jpg', '222.jpg', '294.jpg', '399.jpg', '156.jpg', '298.jpg', '221.jpg', '356.jpg', '144.jpg', '390.jpg', '339.jpg', '244.jpg', '389.jpg', '326.jpg', '307.jpg', '203.jpg', '142.jpg', '392.jpg', '215.jpg', '314.jpg', '350.jpg', '378.jpg', '212.jpg', '332.jpg', '141.jpg', '210.jpg', '209.jpg', '297.jpg', '336.jpg', '305.jpg', '349.jpg', '196.jpg', '290.jpg', '206.jpg', '266.jpg', '355.jpg', '354.jpg', '216.jpg', '311.jpg', '281.jpg', '275.jpg', '245.jpg', '341.jpg', '398.jpg', '331.jpg', '372.jpg', '248.jpg', '329.jpg', '253.jpg', '204.jpg', '247.jpg', '274.jpg', '189.jpg', '383.jpg', '232.jpg', '218.jpg', '328.jpg', '285.jpg', '377.jpg', '338.jpg', '276.jpg', '320.jpg', '273.jpg', '195.jpg', '386.jpg', '162.jpg', '184.jpg', '267.jpg', '272.jpg', '367.jpg', '322.jpg', '213.jpg', '388.jpg', '176.jpg', '268.jpg', '261.jpg', '227.jpg', '225.jpg', '301.jpg', '381.jpg', '342.jpg', '165.jpg', '316.jpg', '323.jpg', '340.jpg', '167.jpg', '358.jpg', '246.jpg', '397.jpg', '270.jpg', '337.jpg', '191.jpg', '194.jpg', '368.jpg', '324.jpg', '385.jpg', '230.jpg', '346.jpg', '170.jpg', '177.jpg']\n",
            "__________\n",
            "image/test\n",
            "['proper', 'broken']\n",
            "__________\n",
            "image/test/proper\n",
            "['1.jpg', '7.jpg', '2.jpg', '5.jpg', '9.jpg', '4.jpg', '10.jpg', '6.jpg', '8.jpg', '3.jpg']\n",
            "__________\n",
            "image/test/broken\n",
            "['146.jpg', '235.jpg', '241.jpg', '242.jpg', '237.jpg', '238.jpg', '236.jpg', '240.jpg', '239.jpg', '243.jpg']\n",
            "__________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UzrSji1XpmB0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 1. Loading the Dataset"
      ]
    },
    {
      "metadata": {
        "id": "qfFm71cLzLES",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "- For now, we will load an image to an single array variable with \n",
        "\n",
        "    (batch,32,32,3) : (number of images, width px, height px, rgb channel dimentions)\n",
        "\n",
        "    in case of gray scale images, it'll be : (batch,32,32,1)\n",
        "    \n",
        "- For class label, we define an array of shape 2: [1, 0], which the first element is the probability of the image being \"proper\" class, while the second as \"broken class\".\n",
        "    So the label paired with each image will be either assigned an array of [1,0] or [0,1]"
      ]
    },
    {
      "metadata": {
        "id": "8DpAAQAwuagB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1-1. Everything to memory"
      ]
    },
    {
      "metadata": {
        "id": "juwpxX7Pp4wS",
        "colab_type": "code",
        "outputId": "a9f48d4b-70be-4a11-9f6f-eddda15227b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "jvcwT_WF5q28",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1-1-1. Relatively manual"
      ]
    },
    {
      "metadata": {
        "id": "v_BAA9i7yBcI",
        "colab_type": "code",
        "outputId": "ca863700-ea32-4311-95fa-22e192e20510",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "cell_type": "code",
      "source": [
        "#note excuse for the .DS_Store contamination in the dataset. to remove the file after obtaining lists using os.listdir,\n",
        "#do..... paths = [x for x in paths if x.endswith(\".jpg\")]\n",
        "\n",
        "x = []\n",
        "y = []\n",
        "\n",
        "test_x = []\n",
        "test_y = []\n",
        "\n",
        "paths = os.listdir(\"image/train/proper\")\n",
        "paths = [x for x in paths if x.endswith(\".jpg\")]\n",
        "for path in paths:\n",
        "    img_path = os.path.join(\"image/train/proper\",path)\n",
        "    img = load_img(img_path, grayscale=False, color_mode='rgb', target_size=(32,32), interpolation='nearest')\n",
        "    img = img_to_array(img)\n",
        "    img /= 255 \n",
        "    x.append(img)\n",
        "    y.append([1,0])\n",
        "    \n",
        "paths = os.listdir(\"image/train/broken\")\n",
        "paths = [x for x in paths if x.endswith(\".jpg\")]\n",
        "for path in paths:\n",
        "    img_path = os.path.join(\"image/train/broken\",path)\n",
        "    img = load_img(img_path, grayscale=False, color_mode='rgb', target_size=(32,32), interpolation='nearest')\n",
        "    img = img_to_array(img)\n",
        "    img /= 255 \n",
        "    x.append(img)\n",
        "    y.append([0,1])\n",
        "\n",
        "paths = os.listdir(\"image/test/proper\")\n",
        "paths = [x for x in paths if x.endswith(\".jpg\")]\n",
        "for path in paths:\n",
        "    img_path = os.path.join(\"image/test/proper\",path)\n",
        "    img = load_img(img_path, grayscale=False, color_mode='rgb', target_size=(32,32), interpolation='nearest')\n",
        "    img = img_to_array(img)\n",
        "    img /= 255 \n",
        "    test_x.append(img)\n",
        "    test_y.append([1,0])\n",
        "    \n",
        "paths = os.listdir(\"image/test/broken\")\n",
        "paths = [x for x in paths if x.endswith(\".jpg\")]\n",
        "for path in paths:\n",
        "    img_path = os.path.join(\"image/test/broken\",path)\n",
        "    img = load_img(img_path, grayscale=False, color_mode='rgb', target_size=(32,32), interpolation='nearest')\n",
        "    img = img_to_array(img)\n",
        "    img /= 255.\n",
        "    test_x.append(img)\n",
        "    test_y.append([0,1])\n",
        "    \n",
        "#convert to numpy array\n",
        "x = np.array(x)\n",
        "y = np.array(y)\n",
        "test_x = np.array(test_x)\n",
        "test_y = np.array(test_y)\n",
        "\n",
        "#split train and validation\n",
        "train_x, valid_x, train_y, valid_y = train_test_split(x, y, test_size=0.2, random_state=1,stratify = y)\n",
        "\n",
        "#check array size\n",
        "print(train_x.shape,train_y.shape)\n",
        "print(valid_x.shape,valid_y.shape)\n",
        "print(test_x.shape,test_y.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(301, 32, 32, 3) (301, 2)\n",
            "(76, 32, 32, 3) (76, 2)\n",
            "(20, 32, 32, 3) (20, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "P3wN4_CG5uRF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1-2-1. Utilizing loops while data importing for code clarity"
      ]
    },
    {
      "metadata": {
        "id": "IoGhRoX_7U6h",
        "colab_type": "code",
        "outputId": "629f7aeb-77a4-4f79-edcd-a9d4b4836b54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "cell_type": "code",
      "source": [
        "parent_dir = \"image\"\n",
        "labels = [\"proper\",\"broken\"]\n",
        "datasets = [\"train\",\"test\"]\n",
        "\n",
        "x = []\n",
        "y = []\n",
        "test_x = []\n",
        "test_y = []\n",
        "\n",
        "for dataset in datasets:\n",
        "    for label in labels:\n",
        "        doi = os.path.join(parent_dir,dataset,label)\n",
        "        paths = os.listdir(doi)\n",
        "        paths = [x for x in paths if x.endswith(\".jpg\")]\n",
        "        for path in paths:\n",
        "            img_path = os.path.join(doi,path)\n",
        "            img = load_img(img_path, grayscale=False, color_mode='rgb', target_size=(32,32), interpolation='nearest')\n",
        "            img = img_to_array(img)\n",
        "            img /= 255.\n",
        "            \n",
        "            if label is \"proper\":\n",
        "                idx = 0\n",
        "            else:\n",
        "                idx = 1\n",
        "            \n",
        "            if dataset is \"train\":\n",
        "                x.append(img)\n",
        "                y.append(idx)\n",
        "            else:\n",
        "                test_x.append(img)\n",
        "                test_y.append(idx)\n",
        "\n",
        "x = np.array(x)\n",
        "y = np.array(y)\n",
        "test_x = np.array(test_x)\n",
        "test_y = np.array(test_y)\n",
        "\n",
        "#this function converts numbers to one hot labels. ex. 0 -> [1,0,0] 1->[0,1,0], 2->[0,0,1]\n",
        "y = to_categorical(y,num_classes=2)\n",
        "test_y = to_categorical(test_y,num_classes=2)\n",
        "\n",
        "train_x, valid_x, train_y, valid_y = train_test_split(x, y, test_size=0.2, random_state=1,stratify = y)\n",
        "\n",
        "print(train_x.shape,train_y.shape)\n",
        "print(valid_x.shape,valid_y.shape)\n",
        "print(test_x.shape,test_y.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(301, 32, 32, 3) (301, 2)\n",
            "(76, 32, 32, 3) (76, 2)\n",
            "(20, 32, 32, 3) (20, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "s3WUMDtA8jM0"
      },
      "cell_type": "markdown",
      "source": [
        "## 1-2. Using ImageDatagenerator"
      ]
    },
    {
      "metadata": {
        "id": "pvWBmqSX7UN3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Using the ImageDatagenerator of Keras allows users to not load everything into memory\\*.\n",
        "It will only store where the files are, and how it will be preprocessed in training.\n",
        "ImageDatagenerator will read and yield small batches of images and corresponding labels upon iteration.\n",
        "This is convineient when the input dataset is large and can not be loaded into memory.\n",
        "\n",
        "\\* It can be combined with data loaded in memory. see the later section."
      ]
    },
    {
      "metadata": {
        "id": "JwHktBfV-Lv7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1-2-1. When the folder structure corresponds to the class label"
      ]
    },
    {
      "metadata": {
        "id": "mNRwyctg7UY-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#use the newest imagedatagenerator class from keras_preprocessing\n",
        "#from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras_preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Tpzr49gP-kPj",
        "colab_type": "code",
        "outputId": "45e77d4f-bb18-44db-c398-f55ba96ea24a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "cell_type": "code",
      "source": [
        "#for train and validation\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale = 1/255.,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "#for test\n",
        "test_datagen= ImageDataGenerator(\n",
        "    rescale = 1/255.\n",
        ")\n",
        "\n",
        "print(\"preparing generators\")\n",
        "\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    directory = \"image/train\",\n",
        "    target_size=(32,32),\n",
        "    batch_size=32, #the number of images included should be divisable by the batch_size as possible. run the cell once, and change the value if not.\n",
        "    classes= [\"proper\",\"broken\"],\n",
        "    class_mode= \"categorical\",\n",
        "    subset=\"training\"\n",
        ")\n",
        "\n",
        "valid_generator = datagen.flow_from_directory(\n",
        "    directory = \"image/train\",\n",
        "    target_size=(32,32),\n",
        "    batch_size=25,\n",
        "    classes= [\"proper\",\"broken\"],\n",
        "    class_mode= \"categorical\",\n",
        "    subset=\"validation\",\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    directory = \"image/test\",\n",
        "    target_size=(32,32),\n",
        "    batch_size=20,\n",
        "    classes= [\"proper\",\"broken\"],\n",
        "    class_mode= \"categorical\",\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "preparing generators\n",
            "Found 302 images belonging to 2 classes.\n",
            "Found 75 images belonging to 2 classes.\n",
            "Found 20 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "rwSjlR3OBYNk"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 1-2-2. When the folder structure do not correspond to the class label (or unknown) and instead have a csv with annotation information"
      ]
    },
    {
      "metadata": {
        "id": "IsvweJ17BefC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "euKbfAzoFIVz",
        "colab_type": "code",
        "outputId": "fd363203-a85d-46ff-b10d-bd4702af7f7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "cell_type": "code",
      "source": [
        "#we read the txt files that hold the path and labels as a dataframe\n",
        "df = pd.read_csv(\"image/train.txt\",delimiter=\"\\t\",header=None,names=[\"path\",\"label\"])\n",
        "test_df = pd.read_csv(\"image/test.txt\",delimiter=\"\\t\",header=None,names=[\"path\",\"label\"])\n",
        "\n",
        "#preview a part of the read dataframe\n",
        "df[:3]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>train/proper/39.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>train/proper/85.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>train/proper/70.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  path  label\n",
              "0  train/proper/39.jpg      0\n",
              "1  train/proper/85.jpg      0\n",
              "2  train/proper/70.jpg      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "metadata": {
        "id": "_1-4WkyWaUBp",
        "colab_type": "code",
        "outputId": "bf26da5b-83f2-48fe-b481-788a70ba3192",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "cell_type": "code",
      "source": [
        "#let's convert the path to absolute path in the dataframe\n",
        "#do not run the cell twice as prefix will be repeatidly added. run the above cell to reset\n",
        "\n",
        "#absolute path of image folder\n",
        "prefix = os.path.abspath(\"image\") + \"/\"\n",
        "\n",
        "df[\"path\"] = prefix + df[\"path\"]\n",
        "test_df[\"path\"] = prefix + test_df[\"path\"]\n",
        "\n",
        "test_df[:3]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/image/test/proper/5.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/image/test/proper/3.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/image/test/proper/10.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                path  label\n",
              "0   /content/image/test/proper/5.jpg      0\n",
              "1   /content/image/test/proper/3.jpg      0\n",
              "2  /content/image/test/proper/10.jpg      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "metadata": {
        "id": "NLIgaLLLUgix",
        "colab_type": "code",
        "outputId": "1a6450ec-0932-441d-de35-7233b65d7210",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "cell_type": "code",
      "source": [
        "#for train and validation\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale = 1/255.,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "#for test\n",
        "test_datagen= ImageDataGenerator(\n",
        "    rescale = 1/255.\n",
        ")\n",
        "\n",
        "print(\"preparing generators\")\n",
        "\n",
        "train_generator = datagen.flow_from_dataframe(\n",
        "    dataframe = df,\n",
        "    x_col=\"path\",\n",
        "    y_col=\"label\",\n",
        "    target_size=(32,32),\n",
        "    batch_size=35, #the number of images included should be divisable by the batch_size as possible. run the cell once, and change the value if not.\n",
        "    class_mode= \"categorical\",\n",
        "    subset=\"training\",\n",
        ")\n",
        "\n",
        "valid_generator = datagen.flow_from_dataframe(\n",
        "    dataframe = df,\n",
        "    x_col=\"path\",\n",
        "    y_col=\"label\",\n",
        "    target_size=(32,32),\n",
        "    batch_size=25,\n",
        "    class_mode= \"categorical\",\n",
        "    subset=\"validation\",\n",
        ")\n",
        "test_generator = test_datagen.flow_from_dataframe(\n",
        "    dataframe = test_df,\n",
        "    x_col=\"path\",\n",
        "    y_col=\"label\",\n",
        "    target_size=(32,32),\n",
        "    batch_size=20,\n",
        "    class_mode= \"categorical\"\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "preparing generators\n",
            "Found 302 images belonging to 2 classes.\n",
            "Found 75 images belonging to 2 classes.\n",
            "Found 20 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ota8ZDS8cq2B",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 2. Build the Convolutional Neural Network"
      ]
    },
    {
      "metadata": {
        "id": "QmtzeNxiczbL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 2-1. Sequential Model way (1)"
      ]
    },
    {
      "metadata": {
        "id": "AJfJ8c8vddbG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras.backend as K\n",
        "from keras.models import Sequential\n",
        "from keras import layers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LZIfveZXcvc7",
        "colab_type": "code",
        "outputId": "0c447ab3-42aa-4a13-cbe6-d9c390e4ee25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        }
      },
      "cell_type": "code",
      "source": [
        "K.clear_session()#not must, but preferred if you are repeatingly running model construction cells for resetting.\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(\n",
        "    layers.Conv2D(16,(3,3),input_shape=(32,32,3),name=\"conv1\",activation=\"relu\",padding=\"same\")\n",
        ")\n",
        "model.add(layers.MaxPool2D((2,2),name=\"pool1\"))\n",
        "model.add(layers.Dropout(0.2))\n",
        "model.add(layers.Conv2D(32,(3,3),name=\"conv2\",padding=\"same\"))   \n",
        "#activation layer can be seperately added\n",
        "model.add(layers.Activation(\"relu\"))\n",
        "model.add(layers.MaxPool2D((2,2),name=\"pool2\"))\n",
        "model.add(layers.Dropout(0.2))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(32,activation=\"relu\"))\n",
        "model.add(layers.Dense(2))\n",
        "model.add(layers.Activation(\"softmax\",name=\"prediction\"))\n",
        "\n",
        "model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics=[\"acc\"])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1 (Conv2D)               (None, 32, 32, 16)        448       \n",
            "_________________________________________________________________\n",
            "pool1 (MaxPooling2D)         (None, 16, 16, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 16, 16, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2 (Conv2D)               (None, 16, 16, 32)        4640      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "pool2 (MaxPooling2D)         (None, 8, 8, 32)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 8, 8, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                65568     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 2)                 66        \n",
            "_________________________________________________________________\n",
            "preprediction (Activation)   (None, 2)                 0         \n",
            "=================================================================\n",
            "Total params: 70,722\n",
            "Trainable params: 70,722\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "2-jsAeD-f9py"
      },
      "cell_type": "markdown",
      "source": [
        "## 2-2. Sequential Model way (2)"
      ]
    },
    {
      "metadata": {
        "id": "RRFgmZaaf_Pp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras.backend as K\n",
        "from keras.models import Sequential\n",
        "from keras import layers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nO117ghbgQUK",
        "colab_type": "code",
        "outputId": "25819d02-5937-4f89-9fd7-d3b3531091f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        }
      },
      "cell_type": "code",
      "source": [
        "K.clear_session()#not must, but preferred if you are repeatingly running model construction cells for resetting.\n",
        "\n",
        "\n",
        "model = Sequential([\n",
        "    layers.Conv2D(16,(3,3),name=\"conv1\",input_shape=(32,32,3),activation=\"relu\",padding=\"same\"),   \n",
        "    layers.MaxPool2D((2,2),name=\"pool1\"),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Conv2D(32,(3,3),name=\"conv2\",padding=\"same\"),\n",
        "    layers.Activation(\"relu\"),\n",
        "    layers.MaxPool2D((2,2),name=\"pool2\"),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(32,activation=\"relu\"),\n",
        "    layers.Dense(2),\n",
        "    layers.Activation(\"softmax\",name=\"prediction\")\n",
        "]\n",
        ")\n",
        "\n",
        "model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics=[\"acc\"])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1 (Conv2D)               (None, 32, 32, 16)        448       \n",
            "_________________________________________________________________\n",
            "pool1 (MaxPooling2D)         (None, 16, 16, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 16, 16, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2 (Conv2D)               (None, 16, 16, 32)        4640      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "pool2 (MaxPooling2D)         (None, 8, 8, 32)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 8, 8, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                65568     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 2)                 66        \n",
            "_________________________________________________________________\n",
            "preprediction (Activation)   (None, 2)                 0         \n",
            "=================================================================\n",
            "Total params: 70,722\n",
            "Trainable params: 70,722\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6msqSa4Lh7hH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 2-3. Functional API way"
      ]
    },
    {
      "metadata": {
        "id": "8BcVrGEQh7zx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras.backend as K\n",
        "from keras.models import Model\n",
        "from keras import layers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J0jA7tIeggli",
        "colab_type": "code",
        "outputId": "fa94f9da-2fea-4133-eeb9-b2a208ebd80f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        }
      },
      "cell_type": "code",
      "source": [
        "K.clear_session()#not must, but preferred if you are repeatingly running model construction cells for resetting.\n",
        "\n",
        "inputs = layers.Input(shape=(32,32,3))\n",
        "l = layers.Conv2D(16,(3,3),name=\"conv1\",input_shape=(32,32,3),activation=\"relu\",padding=\"same\")(inputs)\n",
        "l = layers.MaxPool2D((2,2),name=\"pool1\")(l)\n",
        "l = layers.Dropout(0.2)(l)\n",
        "l = layers.Conv2D(32,(3,3),name=\"conv2\",padding=\"same\")(l)\n",
        "l = layers.Activation(\"relu\")(l)\n",
        "l = layers.MaxPool2D((2,2),name=\"pool2\")(l)\n",
        "l = layers.Dropout(0.2)(l)\n",
        "l = layers.Flatten()(l)\n",
        "l = layers.Dense(32,activation=\"relu\")(l)\n",
        "l = layers.Dense(2)(l)\n",
        "outputs = layers.Activation(\"softmax\",name=\"prediction\")(l)\n",
        "\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics=[\"acc\"])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv1 (Conv2D)               (None, 32, 32, 16)        448       \n",
            "_________________________________________________________________\n",
            "pool1 (MaxPooling2D)         (None, 16, 16, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 16, 16, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2 (Conv2D)               (None, 16, 16, 32)        4640      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "pool2 (MaxPooling2D)         (None, 8, 8, 32)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 8, 8, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                65568     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 2)                 66        \n",
            "_________________________________________________________________\n",
            "preprediction (Activation)   (None, 2)                 0         \n",
            "=================================================================\n",
            "Total params: 70,722\n",
            "Trainable params: 70,722\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yvgBexVrWlgA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 3. Training "
      ]
    },
    {
      "metadata": {
        "id": "o_ume6MDWtXC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## If dataset is loaded in memory"
      ]
    },
    {
      "metadata": {
        "id": "UqphN5w1XDOM",
        "colab_type": "code",
        "outputId": "22b14e97-672f-4799-e04e-4bc9d826d7ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "cell_type": "code",
      "source": [
        "history = model.fit(train_x, train_y, batch_size=32, epochs=5, validation_data = (valid_x,valid_y))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 301 samples, validate on 76 samples\n",
            "Epoch 1/5\n",
            "301/301 [==============================] - 1s 2ms/step - loss: 0.5311 - acc: 0.8206 - val_loss: 0.2263 - val_acc: 1.0000\n",
            "Epoch 2/5\n",
            "301/301 [==============================] - 0s 256us/step - loss: 0.0622 - acc: 0.9967 - val_loss: 0.0105 - val_acc: 1.0000\n",
            "Epoch 3/5\n",
            "301/301 [==============================] - 0s 259us/step - loss: 0.0174 - acc: 0.9900 - val_loss: 0.0210 - val_acc: 1.0000\n",
            "Epoch 4/5\n",
            "301/301 [==============================] - 0s 261us/step - loss: 0.0164 - acc: 0.9934 - val_loss: 0.0078 - val_acc: 1.0000\n",
            "Epoch 5/5\n",
            "301/301 [==============================] - 0s 255us/step - loss: 0.0113 - acc: 0.9934 - val_loss: 0.0059 - val_acc: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GsODIrgJWtaB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## If dataset is prepared by ImageDataGenerator"
      ]
    },
    {
      "metadata": {
        "id": "3ONFb0PqYWSn",
        "colab_type": "code",
        "outputId": "f07ad24f-7fa4-43af-df11-0b361bc63134",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "cell_type": "code",
      "source": [
        "history = model.fit_generator(\n",
        "    generator = train_generator,\n",
        "    steps_per_epoch = (train_generator.samples // train_generator.batch_size),\n",
        "    epochs = 5,\n",
        "    validation_data = valid_generator, \n",
        "    validation_steps = (valid_generator.samples // valid_generator.batch_size)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "9/9 [==============================] - 1s 61ms/step - loss: 0.4961 - acc: 0.8217 - val_loss: 0.2562 - val_acc: 1.0000\n",
            "Epoch 2/5\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.1025 - acc: 0.9930 - val_loss: 0.0229 - val_acc: 1.0000\n",
            "Epoch 3/5\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.0222 - acc: 0.9965 - val_loss: 0.0012 - val_acc: 1.0000\n",
            "Epoch 4/5\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 0.0111 - acc: 0.9965 - val_loss: 2.1675e-04 - val_acc: 1.0000\n",
            "Epoch 5/5\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 0.0103 - acc: 0.9930 - val_loss: 0.0023 - val_acc: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2ixfbVWXWtc1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 4. Miscellaneous"
      ]
    },
    {
      "metadata": {
        "id": "EV_Od6csaGmk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 4-1. Evaluate the model"
      ]
    },
    {
      "metadata": {
        "id": "XbjIc0ylaffQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 4-1-1. If dataset is loaded in memory"
      ]
    },
    {
      "metadata": {
        "id": "LTlHO4hBaG4J",
        "colab_type": "code",
        "outputId": "5c0bd479-7bbe-4afc-eefb-7361368b8e43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "cell_type": "code",
      "source": [
        "evaluation = model.evaluate(test_x,test_y)\n",
        "\n",
        "print(model.metrics_names) #in default, it will output loss and accuracy\n",
        "print(evaluation)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r20/20 [==============================] - 0s 255us/step\n",
            "['loss', 'acc']\n",
            "[0.00026693689869716763, 1.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_Vw5o9WbavjK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 4-1-2. If dataset is prepared by ImageDataGenerator"
      ]
    },
    {
      "metadata": {
        "id": "yXjkqGavWs5V",
        "colab_type": "code",
        "outputId": "33bdf4a3-1a87-4c14-fc7a-32b893e7cdb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "evaluation = model.evaluate_generator(test_generator,steps=test_generator.samples // test_generator.batch_size)\n",
        "\n",
        "print(model.metrics_names) #in default, it will output loss and accuracy\n",
        "print(evaluation)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['loss', 'acc']\n",
            "[0.00026693689869716763, 1.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iHcPZ5Q3bLv3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 4-2. Use the model"
      ]
    },
    {
      "metadata": {
        "id": "ZjD1Lgi2cR8r",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 4-2-1. Single Image"
      ]
    },
    {
      "metadata": {
        "id": "kT_0U_O6cSk6",
        "colab_type": "code",
        "outputId": "2af24011-72e0-486a-e5b1-b3094c2294f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "cell_type": "code",
      "source": [
        "img = test_x[0] #the first image in the test dataset\n",
        "print(\"shape of img is:\", img.shape)\n",
        "\n",
        "#add batch dimension so that the model can read it.\n",
        "\n",
        "img = img[np.newaxis,...]\n",
        "#or \n",
        "#img = np.expand_dims(img,axis=-1)\n",
        "print(\"shape of modified img is:\", img.shape)\n",
        "\n",
        "predictions = model.predict(img)\n",
        "predictions_label = np.argmax(predictions, axis=1)\n",
        "\n",
        "print(\"shape of predictions is:\", predictions.shape)\n",
        "print(\"shape of prediction label is:\", predictions_label.shape)\n",
        "\n",
        "print(\"raw prediction result is:\", predictions[0])\n",
        "print(\"prediction label is:\", predictions_label[0])\n",
        "print(\"correct label is:\", np.argmax(test_y[0],axis=0))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape of img is: (32, 32, 3)\n",
            "shape of modified img is: (1, 32, 32, 3)\n",
            "shape of predictions is: (1, 2)\n",
            "shape of prediction label is: (1,)\n",
            "raw prediction result is: [9.9994290e-01 5.7056743e-05]\n",
            "prediction label is: 0\n",
            "correct label is: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sABwsgf4cSMU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 4-2-2. Multiple Images"
      ]
    },
    {
      "metadata": {
        "id": "LYL4uibJcS3i",
        "colab_type": "code",
        "outputId": "17d6504a-932f-4f2b-e03c-4e4eb522b78b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "cell_type": "code",
      "source": [
        "img = test_x[0:5] #the first five image in the test dataset\n",
        "print(\"shape of img is:\",img.shape)\n",
        "\n",
        "predictions = model.predict(img)\n",
        "predictions_label = np.argmax(predictions, axis=1)\n",
        "\n",
        "print(\"shape of predictions is:\", predictions.shape)\n",
        "print(\"shape of prediction label is:\", predictions_label.shape)\n",
        "print(\"____\")\n",
        "print(\"raw prediction result is:\", predictions)\n",
        "print(\"____\")\n",
        "print(\"prediction label is:\", predictions_label)\n",
        "\n",
        "print(\"correct label is:\", np.argmax(test_y[0:5],axis=1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape of img is: (5, 32, 32, 3)\n",
            "shape of predictions is: (5, 2)\n",
            "shape of prediction label is: (5,)\n",
            "____\n",
            "raw prediction result is: [[9.9994290e-01 5.7056692e-05]\n",
            " [9.9999857e-01 1.3985929e-06]\n",
            " [9.9999893e-01 1.0151450e-06]\n",
            " [1.0000000e+00 4.5575961e-09]\n",
            " [9.9999976e-01 2.8438191e-07]]\n",
            "____\n",
            "prediction label is: [0 0 0 0 0]\n",
            "correct label is: [0 0 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mDtzT66vWoKp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}