{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepDrugDiscoveryExpt1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aced125/Coulomb_matrix_for_Drug_discovery/blob/master/CoulombNetV1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "By328x-7JXS6",
        "colab_type": "text"
      },
      "source": [
        "![coulombnet](https://i.ibb.co/zbhw5L7/Coulomb-Net-slides-2.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WskrCDqpVsNz",
        "colab_type": "text"
      },
      "source": [
        "## The Coulomb matrix is defined as:\n",
        "\n",
        "## $ C_{ij} = \\begin{cases}\n",
        " \\frac{Z_i Z_j}{r_{ij}}, & \\text{if } i \\neq j \\\\\n",
        " \\frac{1}{2}Z_{i}^{2.4}, & \\text{if } i = j\n",
        "\\end{cases}$\n",
        "\n",
        "### where $Z_i$ is the nuclear charge of atom $i$ and $r_{ij}$ is the scalar distance between the 3D coordinaters of atom $i$ and atom $j$.\n",
        "\n",
        "By encoding a molecule in this sort of representation, we encode **all the information necessary to solve the Schrodinger Equation** for this molecule, from which we can determine **all** properties of the molecule: atomisation energy, dipole moment, you name it...\n",
        "\n",
        "### Coulomb matrices have been used to successfully construct a map onto atomization energies in the past, which otherwise would be very computationally costly to calculate (using DFT calculations).\n",
        "\n",
        "### See for example: [Montavan et al 2012](https://pdfs.semanticscholar.org/5761/d22bb67798167a832879a473e0ece867df04.pdf)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpTZCtlOCz64",
        "colab_type": "text"
      },
      "source": [
        "![Coulomb_slide_1](https://i.ibb.co/SB1TMy3/Coulomb-Net-slides.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxDJk4-6im6W",
        "colab_type": "text"
      },
      "source": [
        "## In this notebook we attempt to construct a map from the Coulomb matrix onto the chemical binding of a drug to a particular target.\n",
        "\n",
        "### We find that the model predicts binding well, about as well as current state of the art models like the Random Forest classifier. \n",
        "\n",
        "### More testing shall elucidate whether this type of regressor/classifier can predict binding affinity well of very dissimilar molecules (out-of-domain applicability)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKUFB4jMDzk-",
        "colab_type": "text"
      },
      "source": [
        "![Coulomb_slide_2](https://i.ibb.co/SNFmL4Z/Coulomb-Net-slides-1.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NotuJ1vBEl5N",
        "colab_type": "text"
      },
      "source": [
        "## The process is as follows:\n",
        "\n",
        "1. Generate the Coulomb matrix for each molecule\n",
        "2. Convert to a binary input for the neural network\n",
        "3. Train the neural network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAAoUDP7cyJN",
        "colab_type": "text"
      },
      "source": [
        "![Coulomb matrix](https://i.ibb.co/ZLyDvFd/Screenshot-2019-08-05-at-12-04-25.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45rUo6xwe3Yd",
        "colab_type": "text"
      },
      "source": [
        "Source:  ['Montavon, G 2012, 'Learning Invariant Representations of Molecules for\n",
        "Atomization Energy Prediction', NIPS](https://pdfs.semanticscholar.org/5761/d22bb67798167a832879a473e0ece867df04.pdf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qX_B0AeXWmvP",
        "colab_type": "text"
      },
      "source": [
        "## Download RDKit into Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvSucSqsMXs9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "5820858c-9f77-490a-eedf-795650c1e3e1"
      },
      "source": [
        "# Download RDKit\n",
        "!wget -c https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
        "!chmod +x Miniconda3-latest-Linux-x86_64.sh\n",
        "!time bash ./Miniconda3-latest-Linux-x86_64.sh -b -f -p /usr/local\n",
        "!time conda install -q -y -c conda-forge rdkit"
      ],
      "execution_count": 240,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-08-05 14:20:56--  https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
            "Resolving repo.continuum.io (repo.continuum.io)... 104.18.201.79, 104.18.200.79, 2606:4700::6812:c84f, ...\n",
            "Connecting to repo.continuum.io (repo.continuum.io)|104.18.201.79|:443... connected.\n",
            "HTTP request sent, awaiting response... 416 Requested Range Not Satisfiable\n",
            "\n",
            "    The file is already fully retrieved; nothing to do.\n",
            "\n",
            "PREFIX=/usr/local\n",
            "Unpacking payload ...\n",
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Solving environment: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - _libgcc_mutex==0.1=main\n",
            "    - asn1crypto==0.24.0=py37_0\n",
            "    - bzip2==1.0.8=h7b6447c_0\n",
            "    - ca-certificates==2019.5.15=0\n",
            "    - certifi==2019.6.16=py37_0\n",
            "    - cffi==1.12.3=py37h2e261b9_0\n",
            "    - chardet==3.0.4=py37_1\n",
            "    - conda-package-handling==1.3.11=py37_0\n",
            "    - conda==4.7.10=py37_0\n",
            "    - cryptography==2.7=py37h1ba5d50_0\n",
            "    - idna==2.8=py37_0\n",
            "    - libarchive==3.3.3=h5d8350f_5\n",
            "    - libedit==3.1.20181209=hc058e9b_0\n",
            "    - libffi==3.2.1=hd88cf55_4\n",
            "    - libgcc-ng==9.1.0=hdf63c60_0\n",
            "    - libstdcxx-ng==9.1.0=hdf63c60_0\n",
            "    - libxml2==2.9.9=hea5a465_1\n",
            "    - lz4-c==1.8.1.2=h14c3975_0\n",
            "    - lzo==2.10=h49e0be7_2\n",
            "    - ncurses==6.1=he6710b0_1\n",
            "    - openssl==1.1.1c=h7b6447c_1\n",
            "    - pip==19.1.1=py37_0\n",
            "    - pycosat==0.6.3=py37h14c3975_0\n",
            "    - pycparser==2.19=py37_0\n",
            "    - pyopenssl==19.0.0=py37_0\n",
            "    - pysocks==1.7.0=py37_0\n",
            "    - python-libarchive-c==2.8=py37_11\n",
            "    - python==3.7.3=h0371630_0\n",
            "    - readline==7.0=h7b6447c_5\n",
            "    - requests==2.22.0=py37_0\n",
            "    - ruamel_yaml==0.15.46=py37h14c3975_0\n",
            "    - setuptools==41.0.1=py37_0\n",
            "    - six==1.12.0=py37_0\n",
            "    - sqlite==3.29.0=h7b6447c_0\n",
            "    - tk==8.6.8=hbc83047_0\n",
            "    - tqdm==4.32.1=py_0\n",
            "    - urllib3==1.24.2=py37_0\n",
            "    - wheel==0.33.4=py37_0\n",
            "    - xz==5.2.4=h14c3975_4\n",
            "    - yaml==0.1.7=had09818_2\n",
            "    - zlib==1.2.11=h7b6447c_3\n",
            "    - zstd==1.3.7=h0b5b093_0\n",
            "\n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  openssl            conda-forge::openssl-1.1.1c-h516909a_0 --> pkgs/main::openssl-1.1.1c-h7b6447c_1\n",
            "\n",
            "The following packages will be SUPERSEDED by a higher-priority channel:\n",
            "\n",
            "  ca-certificates    conda-forge::ca-certificates-2019.6.1~ --> pkgs/main::ca-certificates-2019.5.15-0\n",
            "  certifi             conda-forge::certifi-2019.6.16-py37_1 --> pkgs/main::certifi-2019.6.16-py37_0\n",
            "  conda                                         conda-forge --> pkgs/main\n",
            "  lz4-c              conda-forge::lz4-c-1.8.3-he1b5a44_1001 --> pkgs/main::lz4-c-1.8.1.2-h14c3975_0\n",
            "\n",
            "\n",
            "Preparing transaction: / \b\bdone\n",
            "Executing transaction: \\ \b\b| \b\bdone\n",
            "installation finished.\n",
            "WARNING:\n",
            "    You currently have a PYTHONPATH environment variable set. This may cause\n",
            "    unexpected behavior when running the Python interpreter in Miniconda3.\n",
            "    For best results, please verify that your PYTHONPATH only points to\n",
            "    directories of packages that are compatible with the Python interpreter\n",
            "    in Miniconda3: /usr/local\n",
            "\n",
            "real\t0m41.485s\n",
            "user\t0m55.243s\n",
            "sys\t0m6.879s\n",
            "Collecting package metadata (current_repodata.json): ...working... done\n",
            "Solving environment: ...working... done\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - rdkit\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    conda-4.7.10               |           py37_0         3.0 MB  conda-forge\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:         3.0 MB\n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  ca-certificates    pkgs/main::ca-certificates-2019.5.15-0 --> conda-forge::ca-certificates-2019.6.16-hecc5488_0\n",
            "  certifi               pkgs/main::certifi-2019.6.16-py37_0 --> conda-forge::certifi-2019.6.16-py37_1\n",
            "  lz4-c                 pkgs/main::lz4-c-1.8.1.2-h14c3975_0 --> conda-forge::lz4-c-1.8.3-he1b5a44_1001\n",
            "\n",
            "The following packages will be SUPERSEDED by a higher-priority channel:\n",
            "\n",
            "  conda                                           pkgs/main --> conda-forge\n",
            "  openssl              pkgs/main::openssl-1.1.1c-h7b6447c_1 --> conda-forge::openssl-1.1.1c-h516909a_0\n",
            "\n",
            "\n",
            "Preparing transaction: ...working... done\n",
            "Verifying transaction: ...working... done\n",
            "Executing transaction: ...working... done\n",
            "\n",
            "real\t0m14.298s\n",
            "user\t0m12.561s\n",
            "sys\t0m1.336s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKjivByX72bC",
        "colab_type": "text"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmMQogveNEfW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "4636f358-3ae7-425d-dcd8-129996b13f7c"
      },
      "source": [
        "# Append RDKit to system variables\n",
        "import sys\n",
        "import os\n",
        "sys.path.append('/usr/local/lib/python3.7/site-packages/')\n",
        "\n",
        "# Clone this repo to get the data (ADR1B strong and weak ligands)\n",
        "!git clone https://github.com/aced125/RandomMatrixDiscriminant\n",
        "  \n",
        "# Imports\n",
        "import os\n",
        "\n",
        "# RDkit, a chemoinformatics library\n",
        "import rdkit\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem as Chem\n",
        "from rdkit.Chem.Draw import IPythonConsole\n",
        "from rdkit.Chem import PandasTools\n",
        "\n",
        "# Numpy, a quintessential library\n",
        "import numpy as np\n",
        "np.random.seed(42)\n",
        "\n",
        "# Pandas\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import functools\n",
        "\n",
        "# Sklearn imports \n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from tqdm import tqdm\n",
        "from tqdm import trange\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 241,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'RandomMatrixDiscriminant' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTcuH0oPuujj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_dataset(file_name, drop_non_binders = True):\n",
        "    '''\n",
        "    Function to load in the csv dataset from ChEMBL\n",
        "    '''\n",
        "    df = pd.read_csv(file_name, encoding = \"ISO-8859-1\")\n",
        "    \n",
        "    # Converting strings to floats, also set all non-numbers to NaN\n",
        "    df['Standard Vaue'] = pd.to_numeric(df['Standard Value'],errors = 'coerce')\n",
        "\n",
        "    # Drop Nans in affinity column\n",
        "    df.dropna(subset = ['Standard Value'], inplace = True)\n",
        "    df.reset_index(inplace = True)\n",
        "    df = df.drop('index',axis = 1)\n",
        "    \n",
        "    # Filtering for only activities recorded in nanomolar affinity\n",
        "    df = df[df['Standard Units'] == 'nM']    \n",
        "\n",
        "    # Dropping any molecules that don't have a SMILES\n",
        "    df = df.dropna(subset = ['Canonical Smiles'])\n",
        "    \n",
        "    # Considering only the binders (compounds with affinities of less than 1000nM)\n",
        "    if drop_non_binders:\n",
        "        df = df[df['Standard Value'] < 1000]\n",
        "    \n",
        "    # Dropping duplicate molecules\n",
        "    df = df.drop_duplicates(subset = 'Canonical Smiles', keep = 'first')\n",
        "    \n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kK62T7ubs00G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train_test = load_dataset('/content/RandomMatrixDiscriminant/adr1b_chembl.csv', False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBB_AVHbXcMN",
        "colab_type": "text"
      },
      "source": [
        "## The dataframe has the standard value (binding affinity in nM) of the drug, as well as its SMILES string, which we will use to get a view of the molecule, and eventually encode it into its Coulomb matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CDN-WC5QD5-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d014b2a2-121b-46e0-bf25-b73db609faee"
      },
      "source": [
        "df_train_test[['Standard Value','Canonical Smiles']]"
      ],
      "execution_count": 243,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Standard Value</th>\n",
              "      <th>Canonical Smiles</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1000.00</td>\n",
              "      <td>CCCCCCCCNC(=O)N1CCc2cc(ccc12)S(=O)(=O)Nc3ccccc3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10000.00</td>\n",
              "      <td>COc1ccc(cc1OC)[C@@H](Cc2ccccc2)NC[C@H](O)Cc3cc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6000.00</td>\n",
              "      <td>COc1ccc(cc1)[C@@H](Cc2ccccc2)NC[C@@H](O)Cc3ccc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>730.00</td>\n",
              "      <td>COc1ccc(cc1)[C@H](CCc2ccccc2)NC[C@H](O)Cc3ccc(...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3981.07</td>\n",
              "      <td>O[C@@H](CNCCNc1cccc(c1)c2sccc2C(=O)O)c3cccc(Cl)c3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>19.95</td>\n",
              "      <td>C[C@H](CNc1ccc(cc1)c2nc(cs2)C(=O)O)NC[C@H](O)c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>111000.00</td>\n",
              "      <td>[Na+].[Na+].C[C@H](Cc1ccc2OC(Oc2c1)(C(=O)[O-])...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>186.00</td>\n",
              "      <td>CC(C)NCC(O)COc1ccc(C)c2CCCc12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>310.00</td>\n",
              "      <td>C[C@H](Cc1ccc(OCC(=O)NO)cc1)NC[C@H](O)c2cccc(C...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>580.00</td>\n",
              "      <td>CCCCCCCCc1onc(n1)N2CCc3cc(ccc23)S(=O)(=O)Nc4cc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1800.00</td>\n",
              "      <td>CCCCCCc1ccc(nc1)N2CCc3cc(ccc23)S(=O)(=O)Nc4ccccc4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>100000.00</td>\n",
              "      <td>COc1ccc(cc1)S(=O)(=O)N2CCC(CC2)NC[C@H](O)COc3c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>794.33</td>\n",
              "      <td>C[C@H](CNc1cccc(CCS(=O)(=O)NS(=O)(=O)c2ccccc2)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>2000.00</td>\n",
              "      <td>O[C@@H](CNCCc1ccc(NS(=O)(=O)c2ccc(cc2)c3oc(Cc4...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>1200.00</td>\n",
              "      <td>O[C@@H](CNCCc1ccc(NS(=O)(=O)c2ccc(cc2)c3coc(Cc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>1000.00</td>\n",
              "      <td>O[C@@H](CNCCc1ccc(NS(=O)(=O)c2ccc(cc2)c3oc(CCC...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>2000.00</td>\n",
              "      <td>Nc1ccc(OC[C@@H](O)CNCCc2ccc(NS(=O)(=O)c3ccc(Cl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>2400.00</td>\n",
              "      <td>O[C@@H](CNCCc1ccc(NS(=O)(=O)c2ccc(cc2)c3coc(Cc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>1500.00</td>\n",
              "      <td>CS(=O)(=O)Nc1cc(C[C@H](O)CN[C@H](Cc2ccccc2)c3c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>800.00</td>\n",
              "      <td>Cc1cc(ccc1c2ccc3CC[C@@H](Cc3c2)NC[C@H](O)c4ccc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>620.00</td>\n",
              "      <td>O[C@@H](CN[C@H]1CCc2ccc(cc2C1)c3ccc(cc3)C(=O)O...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>1500.00</td>\n",
              "      <td>O[C@@H](CN[C@H]1CCc2ccc(OCC(=O)O)cc2C1)c3cccc(...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>97.00</td>\n",
              "      <td>O[C@@H](CNCCOc1ccc(cc1)c2csc(n2)c3ccncc3)c4cccnc4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>100.00</td>\n",
              "      <td>C[C@H](CNc1ccc(cc1)c2sccc2C(=O)O)NC[C@H](O)c3c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>100.00</td>\n",
              "      <td>C[C@H](CNc1cccc(c1)c2occc2C(=O)O)NC[C@H](O)c3c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>12.02</td>\n",
              "      <td>C[C@H](CNc1ccc(cc1)c2csc(n2)C(=O)O)NC[C@H](O)c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>12.59</td>\n",
              "      <td>C[C@H](CNc1ccc(cc1)c2occ(n2)C(=O)O)NC[C@H](O)c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>10000.00</td>\n",
              "      <td>COc1cccc(c1)[C@@H](Cc2ccccc2)NC[C@H](O)Cc3ccc(...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>1000.00</td>\n",
              "      <td>Cc1ccc(Oc2ccc3CC[C@@H](Cc3c2)NC[C@H](O)c4cccc(...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>3500.00</td>\n",
              "      <td>O[C@@H](CNCCc1ccc(NS(=O)(=O)c2ccc(cc2)c3onc(CO...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2619</th>\n",
              "      <td>630.96</td>\n",
              "      <td>CB1Nc2c(OCC(O)CN(C)C)cccc2C=C1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2622</th>\n",
              "      <td>33.00</td>\n",
              "      <td>CCc1cccc(c1)[C@H]2CCC[C@H]2NC[C@H](O)c3ccc(O)c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2623</th>\n",
              "      <td>40.00</td>\n",
              "      <td>O[C@@H](CN[C@@H]1CCC[C@@H]1C2CCCCC2)c3ccc(O)c4...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2626</th>\n",
              "      <td>20000.00</td>\n",
              "      <td>O[C@@H]([C@H]1CC[C@@H](Cc2ccc(cc2)C(=O)N3CCN(C...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2627</th>\n",
              "      <td>13803.84</td>\n",
              "      <td>C[n+]1c(\\C=C\\c2ccccc2Cl)sc3ccccc13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2629</th>\n",
              "      <td>10000.00</td>\n",
              "      <td>Cc1cc(C)c(NC(=O)OC2CCN(CCCCCCCCCNC[C@H](O)c3cc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2630</th>\n",
              "      <td>47863.01</td>\n",
              "      <td>CCCCC1CCN(CCCN2C(=O)CCc3ccccc23)CC1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2631</th>\n",
              "      <td>21.00</td>\n",
              "      <td>Cc1ccc(CCNC[C@H](O)c2ccc(O)c3NC(=O)Sc23)cc1C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2632</th>\n",
              "      <td>10000.00</td>\n",
              "      <td>CS(=O)(=O)Nc1cc(ccc1O)[C@@H](O)CNCCCCCCCCCN2CC...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2633</th>\n",
              "      <td>20000.00</td>\n",
              "      <td>Nc1nc2[C@@H](CCCCc2s1)C(=O)Nc3ccc(C[C@@H]4CC[C...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2634</th>\n",
              "      <td>10000.00</td>\n",
              "      <td>CS(=O)(=O)Nc1cc(ccc1O)[C@@H](O)CNCCCCCCCCCN2CC...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2635</th>\n",
              "      <td>10000.00</td>\n",
              "      <td>Cc1ccc(NC(=O)OC2CCN(CCCCCCCCCNC[C@H](O)c3ccc(O...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2636</th>\n",
              "      <td>10000.00</td>\n",
              "      <td>CS(=O)(=O)Nc1cc(ccc1O)[C@@H](O)CNCCCCCCCCCN2CC...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2637</th>\n",
              "      <td>10000.00</td>\n",
              "      <td>CS(=O)(=O)Nc1cc(ccc1O)[C@@H](O)CNCCCCCCCCCCCN2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2640</th>\n",
              "      <td>10000.00</td>\n",
              "      <td>CS(=O)(=O)Nc1cc(ccc1O)[C@@H](O)CNCCCCCCCCCN2CC...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2642</th>\n",
              "      <td>227.00</td>\n",
              "      <td>CCc1cc2CC(Cc2cc1CC)NCC(O)c3ccc(O)c4NC(=O)C(=Cc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2646</th>\n",
              "      <td>10000.00</td>\n",
              "      <td>Cc1n[nH]c2cc(OCCNC[C@H](O)c3cccc(NS(=O)(=O)C)c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2656</th>\n",
              "      <td>0.11</td>\n",
              "      <td>COc1ccc(NC(=O)NCCNC[C@H](O)COc2ccccc2C#N)cc1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2660</th>\n",
              "      <td>20000.00</td>\n",
              "      <td>O[C@@H]([C@H]1CC[C@@H](Cc2ccc(cc2)C(=O)N3CCN(C...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2679</th>\n",
              "      <td>20000.00</td>\n",
              "      <td>O[C@@H]([C@H]1CC[C@@H](Cc2ccc(cc2)C(=O)N3CCN(C...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2680</th>\n",
              "      <td>257039.58</td>\n",
              "      <td>C[n+]1c(\\C=C\\Nc2ccccc2)sc3ccccc13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2681</th>\n",
              "      <td>6513.00</td>\n",
              "      <td>Clc1ccccc1C(c2ccccc2)(c3ccccc3)n4ccnc4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2682</th>\n",
              "      <td>10000.00</td>\n",
              "      <td>COc1cc(N)c(Cl)cc1C(=O)NC[C@@H]2CCN3CCC[C@@H]23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2688</th>\n",
              "      <td>239.88</td>\n",
              "      <td>CC(C)NC(C)C(O)COc1ccc(C)c2CCCc12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2694</th>\n",
              "      <td>10000.00</td>\n",
              "      <td>COC1CN(CCCOc2ccc(F)cc2)CCC1NC(=O)c3cc(Cl)c(N)c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2709</th>\n",
              "      <td>10037.00</td>\n",
              "      <td>COc1ccc(CCN2CCC(CC2)Nc3nc4ccccc4n3Cc5ccc(F)cc5...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2725</th>\n",
              "      <td>1500.00</td>\n",
              "      <td>Oc1cc2CC[C@H]3NCc4ccccc4[C@@H]3c2cc1O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2727</th>\n",
              "      <td>2000.00</td>\n",
              "      <td>Clc1cccc(c1)N2CCNCC2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2729</th>\n",
              "      <td>370.00</td>\n",
              "      <td>CC(C)NC[C@@H](O)COc1cccc2ccccc12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2734</th>\n",
              "      <td>10000.00</td>\n",
              "      <td>COc1ccc2c(c1)[nH]c3c(C)nccc23</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1617 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Standard Value                                   Canonical Smiles\n",
              "0            1000.00    CCCCCCCCNC(=O)N1CCc2cc(ccc12)S(=O)(=O)Nc3ccccc3\n",
              "1           10000.00  COc1ccc(cc1OC)[C@@H](Cc2ccccc2)NC[C@H](O)Cc3cc...\n",
              "2            6000.00  COc1ccc(cc1)[C@@H](Cc2ccccc2)NC[C@@H](O)Cc3ccc...\n",
              "3             730.00  COc1ccc(cc1)[C@H](CCc2ccccc2)NC[C@H](O)Cc3ccc(...\n",
              "4            3981.07  O[C@@H](CNCCNc1cccc(c1)c2sccc2C(=O)O)c3cccc(Cl)c3\n",
              "5              19.95  C[C@H](CNc1ccc(cc1)c2nc(cs2)C(=O)O)NC[C@H](O)c...\n",
              "8          111000.00  [Na+].[Na+].C[C@H](Cc1ccc2OC(Oc2c1)(C(=O)[O-])...\n",
              "9             186.00                      CC(C)NCC(O)COc1ccc(C)c2CCCc12\n",
              "11            310.00  C[C@H](Cc1ccc(OCC(=O)NO)cc1)NC[C@H](O)c2cccc(C...\n",
              "14            580.00  CCCCCCCCc1onc(n1)N2CCc3cc(ccc23)S(=O)(=O)Nc4cc...\n",
              "15           1800.00  CCCCCCc1ccc(nc1)N2CCc3cc(ccc23)S(=O)(=O)Nc4ccccc4\n",
              "17         100000.00  COc1ccc(cc1)S(=O)(=O)N2CCC(CC2)NC[C@H](O)COc3c...\n",
              "18            794.33  C[C@H](CNc1cccc(CCS(=O)(=O)NS(=O)(=O)c2ccccc2)...\n",
              "19           2000.00  O[C@@H](CNCCc1ccc(NS(=O)(=O)c2ccc(cc2)c3oc(Cc4...\n",
              "20           1200.00  O[C@@H](CNCCc1ccc(NS(=O)(=O)c2ccc(cc2)c3coc(Cc...\n",
              "21           1000.00  O[C@@H](CNCCc1ccc(NS(=O)(=O)c2ccc(cc2)c3oc(CCC...\n",
              "22           2000.00  Nc1ccc(OC[C@@H](O)CNCCc2ccc(NS(=O)(=O)c3ccc(Cl...\n",
              "23           2400.00  O[C@@H](CNCCc1ccc(NS(=O)(=O)c2ccc(cc2)c3coc(Cc...\n",
              "26           1500.00  CS(=O)(=O)Nc1cc(C[C@H](O)CN[C@H](Cc2ccccc2)c3c...\n",
              "27            800.00  Cc1cc(ccc1c2ccc3CC[C@@H](Cc3c2)NC[C@H](O)c4ccc...\n",
              "28            620.00  O[C@@H](CN[C@H]1CCc2ccc(cc2C1)c3ccc(cc3)C(=O)O...\n",
              "29           1500.00  O[C@@H](CN[C@H]1CCc2ccc(OCC(=O)O)cc2C1)c3cccc(...\n",
              "30             97.00  O[C@@H](CNCCOc1ccc(cc1)c2csc(n2)c3ccncc3)c4cccnc4\n",
              "31            100.00  C[C@H](CNc1ccc(cc1)c2sccc2C(=O)O)NC[C@H](O)c3c...\n",
              "32            100.00  C[C@H](CNc1cccc(c1)c2occc2C(=O)O)NC[C@H](O)c3c...\n",
              "33             12.02  C[C@H](CNc1ccc(cc1)c2csc(n2)C(=O)O)NC[C@H](O)c...\n",
              "34             12.59  C[C@H](CNc1ccc(cc1)c2occ(n2)C(=O)O)NC[C@H](O)c...\n",
              "35          10000.00  COc1cccc(c1)[C@@H](Cc2ccccc2)NC[C@H](O)Cc3ccc(...\n",
              "36           1000.00  Cc1ccc(Oc2ccc3CC[C@@H](Cc3c2)NC[C@H](O)c4cccc(...\n",
              "40           3500.00  O[C@@H](CNCCc1ccc(NS(=O)(=O)c2ccc(cc2)c3onc(CO...\n",
              "...              ...                                                ...\n",
              "2619          630.96                     CB1Nc2c(OCC(O)CN(C)C)cccc2C=C1\n",
              "2622           33.00  CCc1cccc(c1)[C@H]2CCC[C@H]2NC[C@H](O)c3ccc(O)c...\n",
              "2623           40.00  O[C@@H](CN[C@@H]1CCC[C@@H]1C2CCCCC2)c3ccc(O)c4...\n",
              "2626        20000.00  O[C@@H]([C@H]1CC[C@@H](Cc2ccc(cc2)C(=O)N3CCN(C...\n",
              "2627        13803.84                 C[n+]1c(\\C=C\\c2ccccc2Cl)sc3ccccc13\n",
              "2629        10000.00  Cc1cc(C)c(NC(=O)OC2CCN(CCCCCCCCCNC[C@H](O)c3cc...\n",
              "2630        47863.01                CCCCC1CCN(CCCN2C(=O)CCc3ccccc23)CC1\n",
              "2631           21.00       Cc1ccc(CCNC[C@H](O)c2ccc(O)c3NC(=O)Sc23)cc1C\n",
              "2632        10000.00  CS(=O)(=O)Nc1cc(ccc1O)[C@@H](O)CNCCCCCCCCCN2CC...\n",
              "2633        20000.00  Nc1nc2[C@@H](CCCCc2s1)C(=O)Nc3ccc(C[C@@H]4CC[C...\n",
              "2634        10000.00  CS(=O)(=O)Nc1cc(ccc1O)[C@@H](O)CNCCCCCCCCCN2CC...\n",
              "2635        10000.00  Cc1ccc(NC(=O)OC2CCN(CCCCCCCCCNC[C@H](O)c3ccc(O...\n",
              "2636        10000.00  CS(=O)(=O)Nc1cc(ccc1O)[C@@H](O)CNCCCCCCCCCN2CC...\n",
              "2637        10000.00  CS(=O)(=O)Nc1cc(ccc1O)[C@@H](O)CNCCCCCCCCCCCN2...\n",
              "2640        10000.00  CS(=O)(=O)Nc1cc(ccc1O)[C@@H](O)CNCCCCCCCCCN2CC...\n",
              "2642          227.00  CCc1cc2CC(Cc2cc1CC)NCC(O)c3ccc(O)c4NC(=O)C(=Cc...\n",
              "2646        10000.00  Cc1n[nH]c2cc(OCCNC[C@H](O)c3cccc(NS(=O)(=O)C)c...\n",
              "2656            0.11       COc1ccc(NC(=O)NCCNC[C@H](O)COc2ccccc2C#N)cc1\n",
              "2660        20000.00  O[C@@H]([C@H]1CC[C@@H](Cc2ccc(cc2)C(=O)N3CCN(C...\n",
              "2679        20000.00  O[C@@H]([C@H]1CC[C@@H](Cc2ccc(cc2)C(=O)N3CCN(C...\n",
              "2680       257039.58                  C[n+]1c(\\C=C\\Nc2ccccc2)sc3ccccc13\n",
              "2681         6513.00             Clc1ccccc1C(c2ccccc2)(c3ccccc3)n4ccnc4\n",
              "2682        10000.00     COc1cc(N)c(Cl)cc1C(=O)NC[C@@H]2CCN3CCC[C@@H]23\n",
              "2688          239.88                   CC(C)NC(C)C(O)COc1ccc(C)c2CCCc12\n",
              "2694        10000.00  COC1CN(CCCOc2ccc(F)cc2)CCC1NC(=O)c3cc(Cl)c(N)c...\n",
              "2709        10037.00  COc1ccc(CCN2CCC(CC2)Nc3nc4ccccc4n3Cc5ccc(F)cc5...\n",
              "2725         1500.00              Oc1cc2CC[C@H]3NCc4ccccc4[C@@H]3c2cc1O\n",
              "2727         2000.00                               Clc1cccc(c1)N2CCNCC2\n",
              "2729          370.00                   CC(C)NC[C@@H](O)COc1cccc2ccccc12\n",
              "2734        10000.00                      COc1ccc2c(c1)[nH]c3c(C)nccc23\n",
              "\n",
              "[1617 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 243
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3kVC_1SX6Yp",
        "colab_type": "text"
      },
      "source": [
        "## Select the relevant part of the dataframe, to generate our training and testing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mkItiJBJW4f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get the SMILES strings\n",
        "smiles_train_test = df_train_test['Canonical Smiles']\n",
        "smiles_train_test = smiles_train_test.reset_index()['Canonical Smiles']\n",
        "\n",
        "# Get their respective binding affinities, the quantity we are\n",
        "# trying to predict.\n",
        "affinity_train_test = df_train_test['Standard Value']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-9UlqnIYtOS",
        "colab_type": "text"
      },
      "source": [
        "## Define functions to generate the Coulomb matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSl896mSxbd_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.spatial.distance import cdist\n",
        "def get_coulomb_matrix(numbers, coords):\n",
        "    \"\"\"\n",
        "    Generates the unsorted Coulomb-matrix, given an array of\n",
        "    atom atomic numbers, and atom coordinates in space (these\n",
        "    coordinates must be found through minimization of the\n",
        "    atomic structure)\n",
        "    \"\"\"\n",
        "    top = np.outer(numbers, numbers).astype(np.float64)\n",
        "    r = cdist(coords, coords)\n",
        "\n",
        "    with np.errstate(divide='ignore', invalid='ignore'):\n",
        "        np.divide(top, r, top)\n",
        "    np.fill_diagonal(top, 0.5 * np.array(numbers) ** 2.4)\n",
        "    top[top == np.Infinity] = 0\n",
        "    top[np.isnan(top)] = 0\n",
        "    return top"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bV7ZzIqdhZ67",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def coulomb_generator(smiles):\n",
        "    '''\n",
        "    Given a list of SMILES strings, this function\n",
        "    will return the Coulomb matrices,\n",
        "    as well as the indices of the SMILES list of\n",
        "    molecules that failed to be minimized by MM94 force field\n",
        "    implemented in RDKit.\n",
        "    '''\n",
        "    matrices = []\n",
        "    failed_indices = []\n",
        "    max_el = 0\n",
        "    for idx,smile in enumerate(smiles):\n",
        "        print(idx)\n",
        "        mol = Chem.MolFromSmiles(smile)\n",
        "        mol = Chem.AddHs(mol)\n",
        "        try:\n",
        "          Chem.EmbedMolecule(mol)\n",
        "          AllChem.MMFFOptimizeMolecule(mol)\n",
        "          conf = mol.GetConformer()\n",
        "          n_atoms = mol.GetNumAtoms()\n",
        "          z = np.array([atom.GetAtomicNum() for atom in mol.GetAtoms()])\n",
        "          xyz = conf.GetPositions()\n",
        "          m = get_coulomb_matrix(z,xyz)\n",
        "          \n",
        "          matrices.append(m)\n",
        "          max_el = max(max_el, m.max())\n",
        "          print(max_el)\n",
        "        except:\n",
        "          print('failed_idx:',idx)\n",
        "          failed_indices.append(idx)\n",
        "    \n",
        "    max_atoms = max([m[0].shape[0] for m in matrices])\n",
        "    for index, matrix in enumerate(matrices):\n",
        "        n_atoms = matrix[0].shape[0]\n",
        "        m = np.zeros((max_atoms, max_atoms))\n",
        "        m[:n_atoms, :n_atoms] = matrix\n",
        "        matrices[index] = m\n",
        "        \n",
        "    return matrices, failed_indices"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMDlkDehWSNx",
        "colab_type": "text"
      },
      "source": [
        "## Generate the Coulomb matrices from the SMILES strings of molecules - one Coulomb matrix per molecule"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CYDhIUHkWfO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "bafaae84-2e3e-4831-a3a9-74286049cf39"
      },
      "source": [
        "cmatrices, failed_indices = coulomb_generator(np.array(smiles_train_test))"
      ],
      "execution_count": 248,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "388.0234410266618\n",
            "1\n",
            "388.0234410266618\n",
            "2\n",
            "388.0234410266618\n",
            "3\n",
            "388.0234410266618\n",
            "4\n",
            "448.79438598087216\n",
            "5\n",
            "448.79438598087216\n",
            "6\n",
            "448.79438598087216\n",
            "7\n",
            "448.79438598087216\n",
            "8\n",
            "448.79438598087216\n",
            "9\n",
            "448.79438598087216\n",
            "10\n",
            "448.79438598087216\n",
            "11\n",
            "448.79438598087216\n",
            "12\n",
            "448.79438598087216\n",
            "13\n",
            "448.79438598087216\n",
            "14\n",
            "448.79438598087216\n",
            "15\n",
            "448.79438598087216\n",
            "16\n",
            "448.79438598087216\n",
            "17\n",
            "448.79438598087216\n",
            "18\n",
            "448.79438598087216\n",
            "19\n",
            "448.79438598087216\n",
            "20\n",
            "448.79438598087216\n",
            "21\n",
            "448.79438598087216\n",
            "22\n",
            "448.79438598087216\n",
            "23\n",
            "448.79438598087216\n",
            "24\n",
            "448.79438598087216\n",
            "25\n",
            "448.79438598087216\n",
            "26\n",
            "448.79438598087216\n",
            "27\n",
            "448.79438598087216\n",
            "28\n",
            "448.79438598087216\n",
            "29\n",
            "448.79438598087216\n",
            "30\n",
            "448.79438598087216\n",
            "31\n",
            "448.79438598087216\n",
            "32\n",
            "448.79438598087216\n",
            "33\n",
            "448.79438598087216\n",
            "34\n",
            "448.79438598087216\n",
            "35\n",
            "448.79438598087216\n",
            "36\n",
            "448.79438598087216\n",
            "37\n",
            "448.79438598087216\n",
            "38\n",
            "448.79438598087216\n",
            "39\n",
            "448.79438598087216\n",
            "40\n",
            "448.79438598087216\n",
            "41\n",
            "448.79438598087216\n",
            "42\n",
            "448.79438598087216\n",
            "43\n",
            "448.79438598087216\n",
            "44\n",
            "448.79438598087216\n",
            "45\n",
            "448.79438598087216\n",
            "46\n",
            "448.79438598087216\n",
            "47\n",
            "448.79438598087216\n",
            "48\n",
            "448.79438598087216\n",
            "49\n",
            "448.79438598087216\n",
            "50\n",
            "448.79438598087216\n",
            "51\n",
            "448.79438598087216\n",
            "52\n",
            "448.79438598087216\n",
            "53\n",
            "448.79438598087216\n",
            "54\n",
            "448.79438598087216\n",
            "55\n",
            "448.79438598087216\n",
            "56\n",
            "448.79438598087216\n",
            "57\n",
            "448.79438598087216\n",
            "58\n",
            "448.79438598087216\n",
            "59\n",
            "448.79438598087216\n",
            "60\n",
            "448.79438598087216\n",
            "61\n",
            "448.79438598087216\n",
            "62\n",
            "448.79438598087216\n",
            "63\n",
            "448.79438598087216\n",
            "64\n",
            "448.79438598087216\n",
            "65\n",
            "448.79438598087216\n",
            "66\n",
            "448.79438598087216\n",
            "67\n",
            "448.79438598087216\n",
            "68\n",
            "448.79438598087216\n",
            "69\n",
            "448.79438598087216\n",
            "70\n",
            "448.79438598087216\n",
            "71\n",
            "448.79438598087216\n",
            "72\n",
            "448.79438598087216\n",
            "73\n",
            "448.79438598087216\n",
            "74\n",
            "448.79438598087216\n",
            "75\n",
            "448.79438598087216\n",
            "76\n",
            "448.79438598087216\n",
            "77\n",
            "448.79438598087216\n",
            "78\n",
            "448.79438598087216\n",
            "79\n",
            "448.79438598087216\n",
            "80\n",
            "6874.357144891168\n",
            "81\n",
            "6874.357144891168\n",
            "82\n",
            "6874.357144891168\n",
            "83\n",
            "6874.357144891168\n",
            "84\n",
            "6874.357144891168\n",
            "85\n",
            "6874.357144891168\n",
            "86\n",
            "6874.357144891168\n",
            "87\n",
            "6874.357144891168\n",
            "88\n",
            "6874.357144891168\n",
            "89\n",
            "6874.357144891168\n",
            "90\n",
            "6874.357144891168\n",
            "91\n",
            "6874.357144891168\n",
            "92\n",
            "6874.357144891168\n",
            "93\n",
            "6874.357144891168\n",
            "94\n",
            "6874.357144891168\n",
            "95\n",
            "6874.357144891168\n",
            "96\n",
            "6874.357144891168\n",
            "97\n",
            "6874.357144891168\n",
            "98\n",
            "6874.357144891168\n",
            "99\n",
            "6874.357144891168\n",
            "100\n",
            "6874.357144891168\n",
            "101\n",
            "6874.357144891168\n",
            "102\n",
            "6874.357144891168\n",
            "103\n",
            "6874.357144891168\n",
            "104\n",
            "6874.357144891168\n",
            "105\n",
            "6874.357144891168\n",
            "106\n",
            "6874.357144891168\n",
            "107\n",
            "6874.357144891168\n",
            "108\n",
            "6874.357144891168\n",
            "109\n",
            "6874.357144891168\n",
            "110\n",
            "6874.357144891168\n",
            "111\n",
            "6874.357144891168\n",
            "112\n",
            "6874.357144891168\n",
            "113\n",
            "6874.357144891168\n",
            "114\n",
            "6874.357144891168\n",
            "115\n",
            "6874.357144891168\n",
            "116\n",
            "6874.357144891168\n",
            "117\n",
            "6874.357144891168\n",
            "118\n",
            "6874.357144891168\n",
            "119\n",
            "6874.357144891168\n",
            "120\n",
            "6874.357144891168\n",
            "121\n",
            "6874.357144891168\n",
            "122\n",
            "6874.357144891168\n",
            "123\n",
            "6874.357144891168\n",
            "124\n",
            "6874.357144891168\n",
            "125\n",
            "6874.357144891168\n",
            "126\n",
            "6874.357144891168\n",
            "127\n",
            "6874.357144891168\n",
            "128\n",
            "6874.357144891168\n",
            "129\n",
            "6874.357144891168\n",
            "130\n",
            "6874.357144891168\n",
            "131\n",
            "6874.357144891168\n",
            "132\n",
            "6874.357144891168\n",
            "133\n",
            "6874.357144891168\n",
            "134\n",
            "6874.357144891168\n",
            "135\n",
            "6874.357144891168\n",
            "136\n",
            "6874.357144891168\n",
            "137\n",
            "6874.357144891168\n",
            "138\n",
            "6874.357144891168\n",
            "139\n",
            "6874.357144891168\n",
            "140\n",
            "6874.357144891168\n",
            "141\n",
            "6874.357144891168\n",
            "142\n",
            "6874.357144891168\n",
            "143\n",
            "6874.357144891168\n",
            "144\n",
            "6874.357144891168\n",
            "145\n",
            "6874.357144891168\n",
            "146\n",
            "6874.357144891168\n",
            "147\n",
            "361447.54095890425\n",
            "148\n",
            "361447.54095890425\n",
            "149\n",
            "361447.54095890425\n",
            "150\n",
            "361447.54095890425\n",
            "151\n",
            "361447.54095890425\n",
            "152\n",
            "361447.54095890425\n",
            "153\n",
            "361447.54095890425\n",
            "154\n",
            "361447.54095890425\n",
            "155\n",
            "361447.54095890425\n",
            "156\n",
            "361447.54095890425\n",
            "157\n",
            "361447.54095890425\n",
            "158\n",
            "361447.54095890425\n",
            "159\n",
            "361447.54095890425\n",
            "160\n",
            "361447.54095890425\n",
            "161\n",
            "361447.54095890425\n",
            "162\n",
            "361447.54095890425\n",
            "163\n",
            "361447.54095890425\n",
            "164\n",
            "361447.54095890425\n",
            "165\n",
            "361447.54095890425\n",
            "166\n",
            "361447.54095890425\n",
            "167\n",
            "361447.54095890425\n",
            "168\n",
            "361447.54095890425\n",
            "169\n",
            "361447.54095890425\n",
            "170\n",
            "361447.54095890425\n",
            "171\n",
            "361447.54095890425\n",
            "172\n",
            "361447.54095890425\n",
            "173\n",
            "361447.54095890425\n",
            "174\n",
            "361447.54095890425\n",
            "175\n",
            "361447.54095890425\n",
            "176\n",
            "361447.54095890425\n",
            "177\n",
            "361447.54095890425\n",
            "178\n",
            "361447.54095890425\n",
            "179\n",
            "361447.54095890425\n",
            "180\n",
            "361447.54095890425\n",
            "181\n",
            "361447.54095890425\n",
            "182\n",
            "361447.54095890425\n",
            "183\n",
            "361447.54095890425\n",
            "184\n",
            "361447.54095890425\n",
            "185\n",
            "361447.54095890425\n",
            "186\n",
            "361447.54095890425\n",
            "187\n",
            "361447.54095890425\n",
            "188\n",
            "361447.54095890425\n",
            "189\n",
            "361447.54095890425\n",
            "190\n",
            "361447.54095890425\n",
            "191\n",
            "361447.54095890425\n",
            "192\n",
            "361447.54095890425\n",
            "193\n",
            "361447.54095890425\n",
            "194\n",
            "361447.54095890425\n",
            "195\n",
            "361447.54095890425\n",
            "196\n",
            "361447.54095890425\n",
            "197\n",
            "361447.54095890425\n",
            "198\n",
            "361447.54095890425\n",
            "199\n",
            "361447.54095890425\n",
            "200\n",
            "361447.54095890425\n",
            "201\n",
            "361447.54095890425\n",
            "202\n",
            "361447.54095890425\n",
            "203\n",
            "361447.54095890425\n",
            "204\n",
            "361447.54095890425\n",
            "205\n",
            "361447.54095890425\n",
            "206\n",
            "361447.54095890425\n",
            "207\n",
            "361447.54095890425\n",
            "208\n",
            "361447.54095890425\n",
            "209\n",
            "361447.54095890425\n",
            "210\n",
            "361447.54095890425\n",
            "211\n",
            "361447.54095890425\n",
            "212\n",
            "361447.54095890425\n",
            "213\n",
            "361447.54095890425\n",
            "214\n",
            "361447.54095890425\n",
            "215\n",
            "361447.54095890425\n",
            "216\n",
            "361447.54095890425\n",
            "217\n",
            "361447.54095890425\n",
            "218\n",
            "361447.54095890425\n",
            "219\n",
            "361447.54095890425\n",
            "220\n",
            "361447.54095890425\n",
            "221\n",
            "361447.54095890425\n",
            "222\n",
            "361447.54095890425\n",
            "223\n",
            "361447.54095890425\n",
            "224\n",
            "361447.54095890425\n",
            "225\n",
            "361447.54095890425\n",
            "226\n",
            "361447.54095890425\n",
            "227\n",
            "361447.54095890425\n",
            "228\n",
            "361447.54095890425\n",
            "229\n",
            "361447.54095890425\n",
            "230\n",
            "361447.54095890425\n",
            "231\n",
            "361447.54095890425\n",
            "232\n",
            "361447.54095890425\n",
            "233\n",
            "361447.54095890425\n",
            "234\n",
            "361447.54095890425\n",
            "235\n",
            "361447.54095890425\n",
            "236\n",
            "361447.54095890425\n",
            "237\n",
            "361447.54095890425\n",
            "238\n",
            "361447.54095890425\n",
            "239\n",
            "361447.54095890425\n",
            "240\n",
            "361447.54095890425\n",
            "241\n",
            "361447.54095890425\n",
            "242\n",
            "361447.54095890425\n",
            "243\n",
            "361447.54095890425\n",
            "244\n",
            "361447.54095890425\n",
            "245\n",
            "361447.54095890425\n",
            "246\n",
            "361447.54095890425\n",
            "247\n",
            "361447.54095890425\n",
            "248\n",
            "361447.54095890425\n",
            "249\n",
            "361447.54095890425\n",
            "250\n",
            "361447.54095890425\n",
            "251\n",
            "361447.54095890425\n",
            "252\n",
            "361447.54095890425\n",
            "253\n",
            "361447.54095890425\n",
            "254\n",
            "361447.54095890425\n",
            "255\n",
            "361447.54095890425\n",
            "256\n",
            "361447.54095890425\n",
            "257\n",
            "361447.54095890425\n",
            "258\n",
            "361447.54095890425\n",
            "259\n",
            "361447.54095890425\n",
            "260\n",
            "361447.54095890425\n",
            "261\n",
            "361447.54095890425\n",
            "262\n",
            "361447.54095890425\n",
            "263\n",
            "361447.54095890425\n",
            "264\n",
            "361447.54095890425\n",
            "265\n",
            "361447.54095890425\n",
            "266\n",
            "361447.54095890425\n",
            "267\n",
            "361447.54095890425\n",
            "268\n",
            "361447.54095890425\n",
            "269\n",
            "361447.54095890425\n",
            "270\n",
            "361447.54095890425\n",
            "271\n",
            "361447.54095890425\n",
            "272\n",
            "361447.54095890425\n",
            "273\n",
            "361447.54095890425\n",
            "274\n",
            "361447.54095890425\n",
            "275\n",
            "361447.54095890425\n",
            "276\n",
            "361447.54095890425\n",
            "277\n",
            "361447.54095890425\n",
            "278\n",
            "361447.54095890425\n",
            "279\n",
            "361447.54095890425\n",
            "280\n",
            "361447.54095890425\n",
            "281\n",
            "361447.54095890425\n",
            "282\n",
            "361447.54095890425\n",
            "283\n",
            "361447.54095890425\n",
            "284\n",
            "361447.54095890425\n",
            "285\n",
            "361447.54095890425\n",
            "286\n",
            "361447.54095890425\n",
            "287\n",
            "361447.54095890425\n",
            "288\n",
            "361447.54095890425\n",
            "289\n",
            "361447.54095890425\n",
            "290\n",
            "361447.54095890425\n",
            "291\n",
            "361447.54095890425\n",
            "292\n",
            "361447.54095890425\n",
            "293\n",
            "361447.54095890425\n",
            "294\n",
            "361447.54095890425\n",
            "295\n",
            "361447.54095890425\n",
            "296\n",
            "361447.54095890425\n",
            "297\n",
            "361447.54095890425\n",
            "298\n",
            "361447.54095890425\n",
            "299\n",
            "361447.54095890425\n",
            "300\n",
            "361447.54095890425\n",
            "301\n",
            "361447.54095890425\n",
            "302\n",
            "361447.54095890425\n",
            "303\n",
            "361447.54095890425\n",
            "304\n",
            "361447.54095890425\n",
            "305\n",
            "361447.54095890425\n",
            "306\n",
            "361447.54095890425\n",
            "307\n",
            "361447.54095890425\n",
            "308\n",
            "361447.54095890425\n",
            "309\n",
            "361447.54095890425\n",
            "310\n",
            "361447.54095890425\n",
            "311\n",
            "361447.54095890425\n",
            "312\n",
            "361447.54095890425\n",
            "313\n",
            "361447.54095890425\n",
            "314\n",
            "361447.54095890425\n",
            "315\n",
            "361447.54095890425\n",
            "316\n",
            "361447.54095890425\n",
            "317\n",
            "361447.54095890425\n",
            "318\n",
            "361447.54095890425\n",
            "319\n",
            "361447.54095890425\n",
            "320\n",
            "361447.54095890425\n",
            "321\n",
            "361447.54095890425\n",
            "322\n",
            "361447.54095890425\n",
            "323\n",
            "361447.54095890425\n",
            "324\n",
            "361447.54095890425\n",
            "325\n",
            "361447.54095890425\n",
            "326\n",
            "361447.54095890425\n",
            "327\n",
            "361447.54095890425\n",
            "328\n",
            "361447.54095890425\n",
            "329\n",
            "361447.54095890425\n",
            "330\n",
            "361447.54095890425\n",
            "331\n",
            "361447.54095890425\n",
            "332\n",
            "361447.54095890425\n",
            "333\n",
            "361447.54095890425\n",
            "334\n",
            "361447.54095890425\n",
            "335\n",
            "361447.54095890425\n",
            "336\n",
            "361447.54095890425\n",
            "337\n",
            "361447.54095890425\n",
            "338\n",
            "361447.54095890425\n",
            "339\n",
            "361447.54095890425\n",
            "340\n",
            "361447.54095890425\n",
            "341\n",
            "361447.54095890425\n",
            "342\n",
            "361447.54095890425\n",
            "343\n",
            "361447.54095890425\n",
            "344\n",
            "361447.54095890425\n",
            "345\n",
            "361447.54095890425\n",
            "346\n",
            "361447.54095890425\n",
            "347\n",
            "361447.54095890425\n",
            "348\n",
            "361447.54095890425\n",
            "349\n",
            "361447.54095890425\n",
            "350\n",
            "361447.54095890425\n",
            "351\n",
            "361447.54095890425\n",
            "352\n",
            "361447.54095890425\n",
            "353\n",
            "361447.54095890425\n",
            "354\n",
            "361447.54095890425\n",
            "355\n",
            "361447.54095890425\n",
            "356\n",
            "361447.54095890425\n",
            "357\n",
            "361447.54095890425\n",
            "358\n",
            "361447.54095890425\n",
            "359\n",
            "361447.54095890425\n",
            "360\n",
            "361447.54095890425\n",
            "361\n",
            "361447.54095890425\n",
            "362\n",
            "361447.54095890425\n",
            "363\n",
            "361447.54095890425\n",
            "364\n",
            "361447.54095890425\n",
            "365\n",
            "361447.54095890425\n",
            "366\n",
            "361447.54095890425\n",
            "367\n",
            "361447.54095890425\n",
            "368\n",
            "361447.54095890425\n",
            "369\n",
            "361447.54095890425\n",
            "370\n",
            "361447.54095890425\n",
            "371\n",
            "361447.54095890425\n",
            "372\n",
            "361447.54095890425\n",
            "373\n",
            "361447.54095890425\n",
            "374\n",
            "361447.54095890425\n",
            "375\n",
            "361447.54095890425\n",
            "376\n",
            "361447.54095890425\n",
            "377\n",
            "361447.54095890425\n",
            "378\n",
            "361447.54095890425\n",
            "379\n",
            "361447.54095890425\n",
            "380\n",
            "361447.54095890425\n",
            "381\n",
            "361447.54095890425\n",
            "382\n",
            "361447.54095890425\n",
            "383\n",
            "361447.54095890425\n",
            "384\n",
            "361447.54095890425\n",
            "385\n",
            "361447.54095890425\n",
            "386\n",
            "361447.54095890425\n",
            "387\n",
            "361447.54095890425\n",
            "388\n",
            "361447.54095890425\n",
            "389\n",
            "361447.54095890425\n",
            "390\n",
            "361447.54095890425\n",
            "391\n",
            "361447.54095890425\n",
            "392\n",
            "361447.54095890425\n",
            "393\n",
            "361447.54095890425\n",
            "394\n",
            "361447.54095890425\n",
            "395\n",
            "361447.54095890425\n",
            "396\n",
            "361447.54095890425\n",
            "397\n",
            "361447.54095890425\n",
            "398\n",
            "361447.54095890425\n",
            "399\n",
            "361447.54095890425\n",
            "400\n",
            "361447.54095890425\n",
            "401\n",
            "361447.54095890425\n",
            "402\n",
            "361447.54095890425\n",
            "403\n",
            "361447.54095890425\n",
            "404\n",
            "361447.54095890425\n",
            "405\n",
            "361447.54095890425\n",
            "406\n",
            "361447.54095890425\n",
            "407\n",
            "361447.54095890425\n",
            "408\n",
            "361447.54095890425\n",
            "409\n",
            "361447.54095890425\n",
            "410\n",
            "361447.54095890425\n",
            "411\n",
            "361447.54095890425\n",
            "412\n",
            "361447.54095890425\n",
            "413\n",
            "361447.54095890425\n",
            "414\n",
            "361447.54095890425\n",
            "415\n",
            "361447.54095890425\n",
            "416\n",
            "361447.54095890425\n",
            "417\n",
            "361447.54095890425\n",
            "418\n",
            "361447.54095890425\n",
            "419\n",
            "361447.54095890425\n",
            "420\n",
            "361447.54095890425\n",
            "421\n",
            "361447.54095890425\n",
            "422\n",
            "361447.54095890425\n",
            "423\n",
            "361447.54095890425\n",
            "424\n",
            "361447.54095890425\n",
            "425\n",
            "361447.54095890425\n",
            "426\n",
            "361447.54095890425\n",
            "427\n",
            "361447.54095890425\n",
            "428\n",
            "361447.54095890425\n",
            "429\n",
            "361447.54095890425\n",
            "430\n",
            "361447.54095890425\n",
            "431\n",
            "361447.54095890425\n",
            "432\n",
            "361447.54095890425\n",
            "433\n",
            "361447.54095890425\n",
            "434\n",
            "361447.54095890425\n",
            "435\n",
            "361447.54095890425\n",
            "436\n",
            "361447.54095890425\n",
            "437\n",
            "361447.54095890425\n",
            "438\n",
            "361447.54095890425\n",
            "439\n",
            "361447.54095890425\n",
            "440\n",
            "361447.54095890425\n",
            "441\n",
            "361447.54095890425\n",
            "442\n",
            "361447.54095890425\n",
            "443\n",
            "361447.54095890425\n",
            "444\n",
            "361447.54095890425\n",
            "445\n",
            "361447.54095890425\n",
            "446\n",
            "361447.54095890425\n",
            "447\n",
            "361447.54095890425\n",
            "448\n",
            "361447.54095890425\n",
            "449\n",
            "361447.54095890425\n",
            "450\n",
            "361447.54095890425\n",
            "451\n",
            "361447.54095890425\n",
            "452\n",
            "361447.54095890425\n",
            "453\n",
            "361447.54095890425\n",
            "454\n",
            "361447.54095890425\n",
            "455\n",
            "361447.54095890425\n",
            "456\n",
            "361447.54095890425\n",
            "457\n",
            "361447.54095890425\n",
            "458\n",
            "361447.54095890425\n",
            "459\n",
            "361447.54095890425\n",
            "460\n",
            "361447.54095890425\n",
            "461\n",
            "361447.54095890425\n",
            "462\n",
            "361447.54095890425\n",
            "463\n",
            "361447.54095890425\n",
            "464\n",
            "361447.54095890425\n",
            "465\n",
            "361447.54095890425\n",
            "466\n",
            "361447.54095890425\n",
            "467\n",
            "361447.54095890425\n",
            "468\n",
            "361447.54095890425\n",
            "469\n",
            "361447.54095890425\n",
            "470\n",
            "361447.54095890425\n",
            "471\n",
            "361447.54095890425\n",
            "472\n",
            "361447.54095890425\n",
            "473\n",
            "361447.54095890425\n",
            "474\n",
            "361447.54095890425\n",
            "475\n",
            "361447.54095890425\n",
            "476\n",
            "361447.54095890425\n",
            "477\n",
            "361447.54095890425\n",
            "478\n",
            "361447.54095890425\n",
            "479\n",
            "361447.54095890425\n",
            "480\n",
            "361447.54095890425\n",
            "481\n",
            "361447.54095890425\n",
            "482\n",
            "361447.54095890425\n",
            "483\n",
            "361447.54095890425\n",
            "484\n",
            "361447.54095890425\n",
            "485\n",
            "361447.54095890425\n",
            "486\n",
            "361447.54095890425\n",
            "487\n",
            "361447.54095890425\n",
            "488\n",
            "361447.54095890425\n",
            "489\n",
            "361447.54095890425\n",
            "490\n",
            "361447.54095890425\n",
            "491\n",
            "361447.54095890425\n",
            "492\n",
            "361447.54095890425\n",
            "493\n",
            "361447.54095890425\n",
            "494\n",
            "361447.54095890425\n",
            "495\n",
            "361447.54095890425\n",
            "496\n",
            "361447.54095890425\n",
            "497\n",
            "361447.54095890425\n",
            "498\n",
            "361447.54095890425\n",
            "499\n",
            "361447.54095890425\n",
            "500\n",
            "361447.54095890425\n",
            "501\n",
            "361447.54095890425\n",
            "502\n",
            "361447.54095890425\n",
            "503\n",
            "361447.54095890425\n",
            "504\n",
            "361447.54095890425\n",
            "505\n",
            "361447.54095890425\n",
            "506\n",
            "361447.54095890425\n",
            "507\n",
            "361447.54095890425\n",
            "508\n",
            "361447.54095890425\n",
            "509\n",
            "361447.54095890425\n",
            "510\n",
            "361447.54095890425\n",
            "511\n",
            "361447.54095890425\n",
            "512\n",
            "361447.54095890425\n",
            "513\n",
            "361447.54095890425\n",
            "514\n",
            "361447.54095890425\n",
            "515\n",
            "361447.54095890425\n",
            "516\n",
            "361447.54095890425\n",
            "517\n",
            "361447.54095890425\n",
            "518\n",
            "361447.54095890425\n",
            "519\n",
            "361447.54095890425\n",
            "520\n",
            "361447.54095890425\n",
            "521\n",
            "361447.54095890425\n",
            "522\n",
            "361447.54095890425\n",
            "523\n",
            "361447.54095890425\n",
            "524\n",
            "361447.54095890425\n",
            "525\n",
            "361447.54095890425\n",
            "526\n",
            "361447.54095890425\n",
            "527\n",
            "361447.54095890425\n",
            "528\n",
            "361447.54095890425\n",
            "529\n",
            "361447.54095890425\n",
            "530\n",
            "361447.54095890425\n",
            "531\n",
            "361447.54095890425\n",
            "532\n",
            "361447.54095890425\n",
            "533\n",
            "361447.54095890425\n",
            "534\n",
            "361447.54095890425\n",
            "535\n",
            "361447.54095890425\n",
            "536\n",
            "361447.54095890425\n",
            "537\n",
            "361447.54095890425\n",
            "538\n",
            "361447.54095890425\n",
            "539\n",
            "361447.54095890425\n",
            "540\n",
            "361447.54095890425\n",
            "541\n",
            "361447.54095890425\n",
            "542\n",
            "361447.54095890425\n",
            "543\n",
            "361447.54095890425\n",
            "544\n",
            "361447.54095890425\n",
            "545\n",
            "361447.54095890425\n",
            "546\n",
            "361447.54095890425\n",
            "547\n",
            "361447.54095890425\n",
            "548\n",
            "361447.54095890425\n",
            "549\n",
            "361447.54095890425\n",
            "550\n",
            "361447.54095890425\n",
            "551\n",
            "361447.54095890425\n",
            "552\n",
            "361447.54095890425\n",
            "553\n",
            "361447.54095890425\n",
            "554\n",
            "361447.54095890425\n",
            "555\n",
            "361447.54095890425\n",
            "556\n",
            "361447.54095890425\n",
            "557\n",
            "361447.54095890425\n",
            "558\n",
            "361447.54095890425\n",
            "559\n",
            "failed_idx: 559\n",
            "560\n",
            "361447.54095890425\n",
            "561\n",
            "361447.54095890425\n",
            "562\n",
            "361447.54095890425\n",
            "563\n",
            "361447.54095890425\n",
            "564\n",
            "361447.54095890425\n",
            "565\n",
            "361447.54095890425\n",
            "566\n",
            "361447.54095890425\n",
            "567\n",
            "361447.54095890425\n",
            "568\n",
            "361447.54095890425\n",
            "569\n",
            "361447.54095890425\n",
            "570\n",
            "361447.54095890425\n",
            "571\n",
            "361447.54095890425\n",
            "572\n",
            "361447.54095890425\n",
            "573\n",
            "361447.54095890425\n",
            "574\n",
            "361447.54095890425\n",
            "575\n",
            "361447.54095890425\n",
            "576\n",
            "361447.54095890425\n",
            "577\n",
            "361447.54095890425\n",
            "578\n",
            "361447.54095890425\n",
            "579\n",
            "361447.54095890425\n",
            "580\n",
            "361447.54095890425\n",
            "581\n",
            "361447.54095890425\n",
            "582\n",
            "361447.54095890425\n",
            "583\n",
            "361447.54095890425\n",
            "584\n",
            "361447.54095890425\n",
            "585\n",
            "361447.54095890425\n",
            "586\n",
            "361447.54095890425\n",
            "587\n",
            "361447.54095890425\n",
            "588\n",
            "361447.54095890425\n",
            "589\n",
            "361447.54095890425\n",
            "590\n",
            "361447.54095890425\n",
            "591\n",
            "361447.54095890425\n",
            "592\n",
            "361447.54095890425\n",
            "593\n",
            "361447.54095890425\n",
            "594\n",
            "361447.54095890425\n",
            "595\n",
            "361447.54095890425\n",
            "596\n",
            "361447.54095890425\n",
            "597\n",
            "361447.54095890425\n",
            "598\n",
            "361447.54095890425\n",
            "599\n",
            "361447.54095890425\n",
            "600\n",
            "361447.54095890425\n",
            "601\n",
            "361447.54095890425\n",
            "602\n",
            "361447.54095890425\n",
            "603\n",
            "361447.54095890425\n",
            "604\n",
            "361447.54095890425\n",
            "605\n",
            "361447.54095890425\n",
            "606\n",
            "361447.54095890425\n",
            "607\n",
            "361447.54095890425\n",
            "608\n",
            "361447.54095890425\n",
            "609\n",
            "361447.54095890425\n",
            "610\n",
            "361447.54095890425\n",
            "611\n",
            "361447.54095890425\n",
            "612\n",
            "361447.54095890425\n",
            "613\n",
            "361447.54095890425\n",
            "614\n",
            "361447.54095890425\n",
            "615\n",
            "361447.54095890425\n",
            "616\n",
            "361447.54095890425\n",
            "617\n",
            "361447.54095890425\n",
            "618\n",
            "361447.54095890425\n",
            "619\n",
            "361447.54095890425\n",
            "620\n",
            "361447.54095890425\n",
            "621\n",
            "361447.54095890425\n",
            "622\n",
            "361447.54095890425\n",
            "623\n",
            "361447.54095890425\n",
            "624\n",
            "361447.54095890425\n",
            "625\n",
            "361447.54095890425\n",
            "626\n",
            "361447.54095890425\n",
            "627\n",
            "361447.54095890425\n",
            "628\n",
            "361447.54095890425\n",
            "629\n",
            "361447.54095890425\n",
            "630\n",
            "361447.54095890425\n",
            "631\n",
            "361447.54095890425\n",
            "632\n",
            "361447.54095890425\n",
            "633\n",
            "361447.54095890425\n",
            "634\n",
            "361447.54095890425\n",
            "635\n",
            "361447.54095890425\n",
            "636\n",
            "361447.54095890425\n",
            "637\n",
            "361447.54095890425\n",
            "638\n",
            "361447.54095890425\n",
            "639\n",
            "361447.54095890425\n",
            "640\n",
            "361447.54095890425\n",
            "641\n",
            "361447.54095890425\n",
            "642\n",
            "361447.54095890425\n",
            "643\n",
            "361447.54095890425\n",
            "644\n",
            "361447.54095890425\n",
            "645\n",
            "361447.54095890425\n",
            "646\n",
            "361447.54095890425\n",
            "647\n",
            "361447.54095890425\n",
            "648\n",
            "361447.54095890425\n",
            "649\n",
            "361447.54095890425\n",
            "650\n",
            "361447.54095890425\n",
            "651\n",
            "361447.54095890425\n",
            "652\n",
            "361447.54095890425\n",
            "653\n",
            "361447.54095890425\n",
            "654\n",
            "361447.54095890425\n",
            "655\n",
            "361447.54095890425\n",
            "656\n",
            "361447.54095890425\n",
            "657\n",
            "361447.54095890425\n",
            "658\n",
            "361447.54095890425\n",
            "659\n",
            "361447.54095890425\n",
            "660\n",
            "361447.54095890425\n",
            "661\n",
            "361447.54095890425\n",
            "662\n",
            "361447.54095890425\n",
            "663\n",
            "361447.54095890425\n",
            "664\n",
            "361447.54095890425\n",
            "665\n",
            "361447.54095890425\n",
            "666\n",
            "361447.54095890425\n",
            "667\n",
            "361447.54095890425\n",
            "668\n",
            "361447.54095890425\n",
            "669\n",
            "361447.54095890425\n",
            "670\n",
            "361447.54095890425\n",
            "671\n",
            "361447.54095890425\n",
            "672\n",
            "361447.54095890425\n",
            "673\n",
            "361447.54095890425\n",
            "674\n",
            "361447.54095890425\n",
            "675\n",
            "361447.54095890425\n",
            "676\n",
            "361447.54095890425\n",
            "677\n",
            "361447.54095890425\n",
            "678\n",
            "361447.54095890425\n",
            "679\n",
            "361447.54095890425\n",
            "680\n",
            "361447.54095890425\n",
            "681\n",
            "361447.54095890425\n",
            "682\n",
            "361447.54095890425\n",
            "683\n",
            "361447.54095890425\n",
            "684\n",
            "361447.54095890425\n",
            "685\n",
            "361447.54095890425\n",
            "686\n",
            "361447.54095890425\n",
            "687\n",
            "361447.54095890425\n",
            "688\n",
            "361447.54095890425\n",
            "689\n",
            "361447.54095890425\n",
            "690\n",
            "361447.54095890425\n",
            "691\n",
            "361447.54095890425\n",
            "692\n",
            "361447.54095890425\n",
            "693\n",
            "361447.54095890425\n",
            "694\n",
            "361447.54095890425\n",
            "695\n",
            "361447.54095890425\n",
            "696\n",
            "361447.54095890425\n",
            "697\n",
            "361447.54095890425\n",
            "698\n",
            "361447.54095890425\n",
            "699\n",
            "361447.54095890425\n",
            "700\n",
            "361447.54095890425\n",
            "701\n",
            "361447.54095890425\n",
            "702\n",
            "361447.54095890425\n",
            "703\n",
            "361447.54095890425\n",
            "704\n",
            "361447.54095890425\n",
            "705\n",
            "361447.54095890425\n",
            "706\n",
            "361447.54095890425\n",
            "707\n",
            "361447.54095890425\n",
            "708\n",
            "361447.54095890425\n",
            "709\n",
            "361447.54095890425\n",
            "710\n",
            "361447.54095890425\n",
            "711\n",
            "361447.54095890425\n",
            "712\n",
            "361447.54095890425\n",
            "713\n",
            "361447.54095890425\n",
            "714\n",
            "361447.54095890425\n",
            "715\n",
            "361447.54095890425\n",
            "716\n",
            "361447.54095890425\n",
            "717\n",
            "361447.54095890425\n",
            "718\n",
            "361447.54095890425\n",
            "719\n",
            "361447.54095890425\n",
            "720\n",
            "361447.54095890425\n",
            "721\n",
            "361447.54095890425\n",
            "722\n",
            "361447.54095890425\n",
            "723\n",
            "361447.54095890425\n",
            "724\n",
            "361447.54095890425\n",
            "725\n",
            "361447.54095890425\n",
            "726\n",
            "361447.54095890425\n",
            "727\n",
            "361447.54095890425\n",
            "728\n",
            "361447.54095890425\n",
            "729\n",
            "361447.54095890425\n",
            "730\n",
            "361447.54095890425\n",
            "731\n",
            "361447.54095890425\n",
            "732\n",
            "361447.54095890425\n",
            "733\n",
            "361447.54095890425\n",
            "734\n",
            "361447.54095890425\n",
            "735\n",
            "361447.54095890425\n",
            "736\n",
            "361447.54095890425\n",
            "737\n",
            "361447.54095890425\n",
            "738\n",
            "361447.54095890425\n",
            "739\n",
            "361447.54095890425\n",
            "740\n",
            "361447.54095890425\n",
            "741\n",
            "361447.54095890425\n",
            "742\n",
            "361447.54095890425\n",
            "743\n",
            "361447.54095890425\n",
            "744\n",
            "361447.54095890425\n",
            "745\n",
            "361447.54095890425\n",
            "746\n",
            "361447.54095890425\n",
            "747\n",
            "361447.54095890425\n",
            "748\n",
            "361447.54095890425\n",
            "749\n",
            "361447.54095890425\n",
            "750\n",
            "361447.54095890425\n",
            "751\n",
            "361447.54095890425\n",
            "752\n",
            "361447.54095890425\n",
            "753\n",
            "361447.54095890425\n",
            "754\n",
            "361447.54095890425\n",
            "755\n",
            "361447.54095890425\n",
            "756\n",
            "361447.54095890425\n",
            "757\n",
            "361447.54095890425\n",
            "758\n",
            "361447.54095890425\n",
            "759\n",
            "361447.54095890425\n",
            "760\n",
            "361447.54095890425\n",
            "761\n",
            "361447.54095890425\n",
            "762\n",
            "361447.54095890425\n",
            "763\n",
            "361447.54095890425\n",
            "764\n",
            "361447.54095890425\n",
            "765\n",
            "361447.54095890425\n",
            "766\n",
            "361447.54095890425\n",
            "767\n",
            "361447.54095890425\n",
            "768\n",
            "361447.54095890425\n",
            "769\n",
            "361447.54095890425\n",
            "770\n",
            "361447.54095890425\n",
            "771\n",
            "361447.54095890425\n",
            "772\n",
            "361447.54095890425\n",
            "773\n",
            "361447.54095890425\n",
            "774\n",
            "361447.54095890425\n",
            "775\n",
            "361447.54095890425\n",
            "776\n",
            "361447.54095890425\n",
            "777\n",
            "361447.54095890425\n",
            "778\n",
            "361447.54095890425\n",
            "779\n",
            "361447.54095890425\n",
            "780\n",
            "361447.54095890425\n",
            "781\n",
            "361447.54095890425\n",
            "782\n",
            "361447.54095890425\n",
            "783\n",
            "361447.54095890425\n",
            "784\n",
            "361447.54095890425\n",
            "785\n",
            "361447.54095890425\n",
            "786\n",
            "361447.54095890425\n",
            "787\n",
            "361447.54095890425\n",
            "788\n",
            "361447.54095890425\n",
            "789\n",
            "361447.54095890425\n",
            "790\n",
            "361447.54095890425\n",
            "791\n",
            "361447.54095890425\n",
            "792\n",
            "361447.54095890425\n",
            "793\n",
            "361447.54095890425\n",
            "794\n",
            "361447.54095890425\n",
            "795\n",
            "361447.54095890425\n",
            "796\n",
            "361447.54095890425\n",
            "797\n",
            "361447.54095890425\n",
            "798\n",
            "361447.54095890425\n",
            "799\n",
            "361447.54095890425\n",
            "800\n",
            "361447.54095890425\n",
            "801\n",
            "361447.54095890425\n",
            "802\n",
            "361447.54095890425\n",
            "803\n",
            "361447.54095890425\n",
            "804\n",
            "361447.54095890425\n",
            "805\n",
            "361447.54095890425\n",
            "806\n",
            "361447.54095890425\n",
            "807\n",
            "361447.54095890425\n",
            "808\n",
            "361447.54095890425\n",
            "809\n",
            "361447.54095890425\n",
            "810\n",
            "361447.54095890425\n",
            "811\n",
            "361447.54095890425\n",
            "812\n",
            "361447.54095890425\n",
            "813\n",
            "361447.54095890425\n",
            "814\n",
            "361447.54095890425\n",
            "815\n",
            "361447.54095890425\n",
            "816\n",
            "361447.54095890425\n",
            "817\n",
            "361447.54095890425\n",
            "818\n",
            "361447.54095890425\n",
            "819\n",
            "361447.54095890425\n",
            "820\n",
            "361447.54095890425\n",
            "821\n",
            "361447.54095890425\n",
            "822\n",
            "361447.54095890425\n",
            "823\n",
            "361447.54095890425\n",
            "824\n",
            "361447.54095890425\n",
            "825\n",
            "361447.54095890425\n",
            "826\n",
            "361447.54095890425\n",
            "827\n",
            "361447.54095890425\n",
            "828\n",
            "361447.54095890425\n",
            "829\n",
            "361447.54095890425\n",
            "830\n",
            "361447.54095890425\n",
            "831\n",
            "361447.54095890425\n",
            "832\n",
            "361447.54095890425\n",
            "833\n",
            "361447.54095890425\n",
            "834\n",
            "361447.54095890425\n",
            "835\n",
            "361447.54095890425\n",
            "836\n",
            "361447.54095890425\n",
            "837\n",
            "361447.54095890425\n",
            "838\n",
            "361447.54095890425\n",
            "839\n",
            "361447.54095890425\n",
            "840\n",
            "361447.54095890425\n",
            "841\n",
            "361447.54095890425\n",
            "842\n",
            "361447.54095890425\n",
            "843\n",
            "361447.54095890425\n",
            "844\n",
            "361447.54095890425\n",
            "845\n",
            "361447.54095890425\n",
            "846\n",
            "361447.54095890425\n",
            "847\n",
            "361447.54095890425\n",
            "848\n",
            "361447.54095890425\n",
            "849\n",
            "361447.54095890425\n",
            "850\n",
            "361447.54095890425\n",
            "851\n",
            "361447.54095890425\n",
            "852\n",
            "361447.54095890425\n",
            "853\n",
            "361447.54095890425\n",
            "854\n",
            "361447.54095890425\n",
            "855\n",
            "361447.54095890425\n",
            "856\n",
            "361447.54095890425\n",
            "857\n",
            "361447.54095890425\n",
            "858\n",
            "361447.54095890425\n",
            "859\n",
            "361447.54095890425\n",
            "860\n",
            "361447.54095890425\n",
            "861\n",
            "361447.54095890425\n",
            "862\n",
            "361447.54095890425\n",
            "863\n",
            "361447.54095890425\n",
            "864\n",
            "361447.54095890425\n",
            "865\n",
            "361447.54095890425\n",
            "866\n",
            "361447.54095890425\n",
            "867\n",
            "361447.54095890425\n",
            "868\n",
            "361447.54095890425\n",
            "869\n",
            "361447.54095890425\n",
            "870\n",
            "361447.54095890425\n",
            "871\n",
            "361447.54095890425\n",
            "872\n",
            "361447.54095890425\n",
            "873\n",
            "361447.54095890425\n",
            "874\n",
            "361447.54095890425\n",
            "875\n",
            "361447.54095890425\n",
            "876\n",
            "361447.54095890425\n",
            "877\n",
            "361447.54095890425\n",
            "878\n",
            "361447.54095890425\n",
            "879\n",
            "361447.54095890425\n",
            "880\n",
            "361447.54095890425\n",
            "881\n",
            "361447.54095890425\n",
            "882\n",
            "361447.54095890425\n",
            "883\n",
            "361447.54095890425\n",
            "884\n",
            "361447.54095890425\n",
            "885\n",
            "361447.54095890425\n",
            "886\n",
            "361447.54095890425\n",
            "887\n",
            "361447.54095890425\n",
            "888\n",
            "361447.54095890425\n",
            "889\n",
            "361447.54095890425\n",
            "890\n",
            "361447.54095890425\n",
            "891\n",
            "361447.54095890425\n",
            "892\n",
            "361447.54095890425\n",
            "893\n",
            "361447.54095890425\n",
            "894\n",
            "361447.54095890425\n",
            "895\n",
            "361447.54095890425\n",
            "896\n",
            "361447.54095890425\n",
            "897\n",
            "361447.54095890425\n",
            "898\n",
            "361447.54095890425\n",
            "899\n",
            "361447.54095890425\n",
            "900\n",
            "361447.54095890425\n",
            "901\n",
            "361447.54095890425\n",
            "902\n",
            "361447.54095890425\n",
            "903\n",
            "361447.54095890425\n",
            "904\n",
            "361447.54095890425\n",
            "905\n",
            "361447.54095890425\n",
            "906\n",
            "361447.54095890425\n",
            "907\n",
            "361447.54095890425\n",
            "908\n",
            "361447.54095890425\n",
            "909\n",
            "361447.54095890425\n",
            "910\n",
            "361447.54095890425\n",
            "911\n",
            "361447.54095890425\n",
            "912\n",
            "361447.54095890425\n",
            "913\n",
            "361447.54095890425\n",
            "914\n",
            "361447.54095890425\n",
            "915\n",
            "361447.54095890425\n",
            "916\n",
            "361447.54095890425\n",
            "917\n",
            "361447.54095890425\n",
            "918\n",
            "361447.54095890425\n",
            "919\n",
            "361447.54095890425\n",
            "920\n",
            "361447.54095890425\n",
            "921\n",
            "361447.54095890425\n",
            "922\n",
            "361447.54095890425\n",
            "923\n",
            "361447.54095890425\n",
            "924\n",
            "361447.54095890425\n",
            "925\n",
            "361447.54095890425\n",
            "926\n",
            "361447.54095890425\n",
            "927\n",
            "361447.54095890425\n",
            "928\n",
            "361447.54095890425\n",
            "929\n",
            "361447.54095890425\n",
            "930\n",
            "361447.54095890425\n",
            "931\n",
            "361447.54095890425\n",
            "932\n",
            "361447.54095890425\n",
            "933\n",
            "361447.54095890425\n",
            "934\n",
            "361447.54095890425\n",
            "935\n",
            "361447.54095890425\n",
            "936\n",
            "361447.54095890425\n",
            "937\n",
            "361447.54095890425\n",
            "938\n",
            "361447.54095890425\n",
            "939\n",
            "361447.54095890425\n",
            "940\n",
            "361447.54095890425\n",
            "941\n",
            "361447.54095890425\n",
            "942\n",
            "361447.54095890425\n",
            "943\n",
            "361447.54095890425\n",
            "944\n",
            "361447.54095890425\n",
            "945\n",
            "361447.54095890425\n",
            "946\n",
            "361447.54095890425\n",
            "947\n",
            "361447.54095890425\n",
            "948\n",
            "361447.54095890425\n",
            "949\n",
            "361447.54095890425\n",
            "950\n",
            "361447.54095890425\n",
            "951\n",
            "361447.54095890425\n",
            "952\n",
            "361447.54095890425\n",
            "953\n",
            "361447.54095890425\n",
            "954\n",
            "361447.54095890425\n",
            "955\n",
            "361447.54095890425\n",
            "956\n",
            "361447.54095890425\n",
            "957\n",
            "361447.54095890425\n",
            "958\n",
            "361447.54095890425\n",
            "959\n",
            "361447.54095890425\n",
            "960\n",
            "361447.54095890425\n",
            "961\n",
            "361447.54095890425\n",
            "962\n",
            "361447.54095890425\n",
            "963\n",
            "361447.54095890425\n",
            "964\n",
            "361447.54095890425\n",
            "965\n",
            "361447.54095890425\n",
            "966\n",
            "361447.54095890425\n",
            "967\n",
            "361447.54095890425\n",
            "968\n",
            "361447.54095890425\n",
            "969\n",
            "361447.54095890425\n",
            "970\n",
            "361447.54095890425\n",
            "971\n",
            "361447.54095890425\n",
            "972\n",
            "361447.54095890425\n",
            "973\n",
            "361447.54095890425\n",
            "974\n",
            "361447.54095890425\n",
            "975\n",
            "361447.54095890425\n",
            "976\n",
            "361447.54095890425\n",
            "977\n",
            "361447.54095890425\n",
            "978\n",
            "361447.54095890425\n",
            "979\n",
            "361447.54095890425\n",
            "980\n",
            "361447.54095890425\n",
            "981\n",
            "361447.54095890425\n",
            "982\n",
            "361447.54095890425\n",
            "983\n",
            "361447.54095890425\n",
            "984\n",
            "361447.54095890425\n",
            "985\n",
            "361447.54095890425\n",
            "986\n",
            "361447.54095890425\n",
            "987\n",
            "361447.54095890425\n",
            "988\n",
            "361447.54095890425\n",
            "989\n",
            "361447.54095890425\n",
            "990\n",
            "361447.54095890425\n",
            "991\n",
            "361447.54095890425\n",
            "992\n",
            "361447.54095890425\n",
            "993\n",
            "361447.54095890425\n",
            "994\n",
            "361447.54095890425\n",
            "995\n",
            "361447.54095890425\n",
            "996\n",
            "361447.54095890425\n",
            "997\n",
            "361447.54095890425\n",
            "998\n",
            "361447.54095890425\n",
            "999\n",
            "361447.54095890425\n",
            "1000\n",
            "361447.54095890425\n",
            "1001\n",
            "361447.54095890425\n",
            "1002\n",
            "361447.54095890425\n",
            "1003\n",
            "361447.54095890425\n",
            "1004\n",
            "361447.54095890425\n",
            "1005\n",
            "361447.54095890425\n",
            "1006\n",
            "361447.54095890425\n",
            "1007\n",
            "361447.54095890425\n",
            "1008\n",
            "361447.54095890425\n",
            "1009\n",
            "361447.54095890425\n",
            "1010\n",
            "361447.54095890425\n",
            "1011\n",
            "361447.54095890425\n",
            "1012\n",
            "361447.54095890425\n",
            "1013\n",
            "361447.54095890425\n",
            "1014\n",
            "361447.54095890425\n",
            "1015\n",
            "361447.54095890425\n",
            "1016\n",
            "361447.54095890425\n",
            "1017\n",
            "361447.54095890425\n",
            "1018\n",
            "361447.54095890425\n",
            "1019\n",
            "361447.54095890425\n",
            "1020\n",
            "361447.54095890425\n",
            "1021\n",
            "361447.54095890425\n",
            "1022\n",
            "361447.54095890425\n",
            "1023\n",
            "361447.54095890425\n",
            "1024\n",
            "361447.54095890425\n",
            "1025\n",
            "361447.54095890425\n",
            "1026\n",
            "361447.54095890425\n",
            "1027\n",
            "361447.54095890425\n",
            "1028\n",
            "361447.54095890425\n",
            "1029\n",
            "361447.54095890425\n",
            "1030\n",
            "361447.54095890425\n",
            "1031\n",
            "361447.54095890425\n",
            "1032\n",
            "361447.54095890425\n",
            "1033\n",
            "361447.54095890425\n",
            "1034\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "RDKit ERROR: [14:28:53] UFFTYPER: Unrecognized charge state for atom: 6\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "361447.54095890425\n",
            "1035\n",
            "361447.54095890425\n",
            "1036\n",
            "361447.54095890425\n",
            "1037\n",
            "361447.54095890425\n",
            "1038\n",
            "361447.54095890425\n",
            "1039\n",
            "361447.54095890425\n",
            "1040\n",
            "361447.54095890425\n",
            "1041\n",
            "361447.54095890425\n",
            "1042\n",
            "361447.54095890425\n",
            "1043\n",
            "361447.54095890425\n",
            "1044\n",
            "361447.54095890425\n",
            "1045\n",
            "361447.54095890425\n",
            "1046\n",
            "361447.54095890425\n",
            "1047\n",
            "361447.54095890425\n",
            "1048\n",
            "361447.54095890425\n",
            "1049\n",
            "361447.54095890425\n",
            "1050\n",
            "361447.54095890425\n",
            "1051\n",
            "361447.54095890425\n",
            "1052\n",
            "361447.54095890425\n",
            "1053\n",
            "361447.54095890425\n",
            "1054\n",
            "361447.54095890425\n",
            "1055\n",
            "361447.54095890425\n",
            "1056\n",
            "361447.54095890425\n",
            "1057\n",
            "361447.54095890425\n",
            "1058\n",
            "361447.54095890425\n",
            "1059\n",
            "361447.54095890425\n",
            "1060\n",
            "361447.54095890425\n",
            "1061\n",
            "361447.54095890425\n",
            "1062\n",
            "361447.54095890425\n",
            "1063\n",
            "361447.54095890425\n",
            "1064\n",
            "361447.54095890425\n",
            "1065\n",
            "361447.54095890425\n",
            "1066\n",
            "361447.54095890425\n",
            "1067\n",
            "361447.54095890425\n",
            "1068\n",
            "361447.54095890425\n",
            "1069\n",
            "361447.54095890425\n",
            "1070\n",
            "361447.54095890425\n",
            "1071\n",
            "361447.54095890425\n",
            "1072\n",
            "361447.54095890425\n",
            "1073\n",
            "361447.54095890425\n",
            "1074\n",
            "361447.54095890425\n",
            "1075\n",
            "361447.54095890425\n",
            "1076\n",
            "361447.54095890425\n",
            "1077\n",
            "361447.54095890425\n",
            "1078\n",
            "361447.54095890425\n",
            "1079\n",
            "361447.54095890425\n",
            "1080\n",
            "361447.54095890425\n",
            "1081\n",
            "361447.54095890425\n",
            "1082\n",
            "361447.54095890425\n",
            "1083\n",
            "361447.54095890425\n",
            "1084\n",
            "361447.54095890425\n",
            "1085\n",
            "361447.54095890425\n",
            "1086\n",
            "361447.54095890425\n",
            "1087\n",
            "361447.54095890425\n",
            "1088\n",
            "361447.54095890425\n",
            "1089\n",
            "361447.54095890425\n",
            "1090\n",
            "361447.54095890425\n",
            "1091\n",
            "361447.54095890425\n",
            "1092\n",
            "361447.54095890425\n",
            "1093\n",
            "361447.54095890425\n",
            "1094\n",
            "361447.54095890425\n",
            "1095\n",
            "361447.54095890425\n",
            "1096\n",
            "361447.54095890425\n",
            "1097\n",
            "361447.54095890425\n",
            "1098\n",
            "361447.54095890425\n",
            "1099\n",
            "361447.54095890425\n",
            "1100\n",
            "361447.54095890425\n",
            "1101\n",
            "361447.54095890425\n",
            "1102\n",
            "361447.54095890425\n",
            "1103\n",
            "361447.54095890425\n",
            "1104\n",
            "361447.54095890425\n",
            "1105\n",
            "361447.54095890425\n",
            "1106\n",
            "361447.54095890425\n",
            "1107\n",
            "361447.54095890425\n",
            "1108\n",
            "361447.54095890425\n",
            "1109\n",
            "361447.54095890425\n",
            "1110\n",
            "361447.54095890425\n",
            "1111\n",
            "361447.54095890425\n",
            "1112\n",
            "361447.54095890425\n",
            "1113\n",
            "361447.54095890425\n",
            "1114\n",
            "361447.54095890425\n",
            "1115\n",
            "361447.54095890425\n",
            "1116\n",
            "361447.54095890425\n",
            "1117\n",
            "361447.54095890425\n",
            "1118\n",
            "361447.54095890425\n",
            "1119\n",
            "361447.54095890425\n",
            "1120\n",
            "361447.54095890425\n",
            "1121\n",
            "361447.54095890425\n",
            "1122\n",
            "361447.54095890425\n",
            "1123\n",
            "361447.54095890425\n",
            "1124\n",
            "361447.54095890425\n",
            "1125\n",
            "361447.54095890425\n",
            "1126\n",
            "361447.54095890425\n",
            "1127\n",
            "361447.54095890425\n",
            "1128\n",
            "361447.54095890425\n",
            "1129\n",
            "361447.54095890425\n",
            "1130\n",
            "361447.54095890425\n",
            "1131\n",
            "361447.54095890425\n",
            "1132\n",
            "361447.54095890425\n",
            "1133\n",
            "361447.54095890425\n",
            "1134\n",
            "361447.54095890425\n",
            "1135\n",
            "361447.54095890425\n",
            "1136\n",
            "361447.54095890425\n",
            "1137\n",
            "361447.54095890425\n",
            "1138\n",
            "361447.54095890425\n",
            "1139\n",
            "361447.54095890425\n",
            "1140\n",
            "361447.54095890425\n",
            "1141\n",
            "361447.54095890425\n",
            "1142\n",
            "361447.54095890425\n",
            "1143\n",
            "361447.54095890425\n",
            "1144\n",
            "361447.54095890425\n",
            "1145\n",
            "361447.54095890425\n",
            "1146\n",
            "361447.54095890425\n",
            "1147\n",
            "361447.54095890425\n",
            "1148\n",
            "361447.54095890425\n",
            "1149\n",
            "361447.54095890425\n",
            "1150\n",
            "361447.54095890425\n",
            "1151\n",
            "361447.54095890425\n",
            "1152\n",
            "361447.54095890425\n",
            "1153\n",
            "361447.54095890425\n",
            "1154\n",
            "361447.54095890425\n",
            "1155\n",
            "361447.54095890425\n",
            "1156\n",
            "361447.54095890425\n",
            "1157\n",
            "361447.54095890425\n",
            "1158\n",
            "361447.54095890425\n",
            "1159\n",
            "361447.54095890425\n",
            "1160\n",
            "361447.54095890425\n",
            "1161\n",
            "361447.54095890425\n",
            "1162\n",
            "361447.54095890425\n",
            "1163\n",
            "361447.54095890425\n",
            "1164\n",
            "361447.54095890425\n",
            "1165\n",
            "361447.54095890425\n",
            "1166\n",
            "361447.54095890425\n",
            "1167\n",
            "361447.54095890425\n",
            "1168\n",
            "361447.54095890425\n",
            "1169\n",
            "361447.54095890425\n",
            "1170\n",
            "361447.54095890425\n",
            "1171\n",
            "361447.54095890425\n",
            "1172\n",
            "361447.54095890425\n",
            "1173\n",
            "361447.54095890425\n",
            "1174\n",
            "361447.54095890425\n",
            "1175\n",
            "361447.54095890425\n",
            "1176\n",
            "361447.54095890425\n",
            "1177\n",
            "361447.54095890425\n",
            "1178\n",
            "361447.54095890425\n",
            "1179\n",
            "361447.54095890425\n",
            "1180\n",
            "361447.54095890425\n",
            "1181\n",
            "361447.54095890425\n",
            "1182\n",
            "361447.54095890425\n",
            "1183\n",
            "361447.54095890425\n",
            "1184\n",
            "361447.54095890425\n",
            "1185\n",
            "361447.54095890425\n",
            "1186\n",
            "361447.54095890425\n",
            "1187\n",
            "361447.54095890425\n",
            "1188\n",
            "361447.54095890425\n",
            "1189\n",
            "361447.54095890425\n",
            "1190\n",
            "361447.54095890425\n",
            "1191\n",
            "361447.54095890425\n",
            "1192\n",
            "361447.54095890425\n",
            "1193\n",
            "361447.54095890425\n",
            "1194\n",
            "361447.54095890425\n",
            "1195\n",
            "361447.54095890425\n",
            "1196\n",
            "361447.54095890425\n",
            "1197\n",
            "361447.54095890425\n",
            "1198\n",
            "361447.54095890425\n",
            "1199\n",
            "361447.54095890425\n",
            "1200\n",
            "361447.54095890425\n",
            "1201\n",
            "361447.54095890425\n",
            "1202\n",
            "361447.54095890425\n",
            "1203\n",
            "361447.54095890425\n",
            "1204\n",
            "361447.54095890425\n",
            "1205\n",
            "361447.54095890425\n",
            "1206\n",
            "361447.54095890425\n",
            "1207\n",
            "361447.54095890425\n",
            "1208\n",
            "361447.54095890425\n",
            "1209\n",
            "361447.54095890425\n",
            "1210\n",
            "361447.54095890425\n",
            "1211\n",
            "361447.54095890425\n",
            "1212\n",
            "361447.54095890425\n",
            "1213\n",
            "361447.54095890425\n",
            "1214\n",
            "361447.54095890425\n",
            "1215\n",
            "361447.54095890425\n",
            "1216\n",
            "361447.54095890425\n",
            "1217\n",
            "361447.54095890425\n",
            "1218\n",
            "361447.54095890425\n",
            "1219\n",
            "361447.54095890425\n",
            "1220\n",
            "361447.54095890425\n",
            "1221\n",
            "361447.54095890425\n",
            "1222\n",
            "361447.54095890425\n",
            "1223\n",
            "361447.54095890425\n",
            "1224\n",
            "361447.54095890425\n",
            "1225\n",
            "361447.54095890425\n",
            "1226\n",
            "361447.54095890425\n",
            "1227\n",
            "361447.54095890425\n",
            "1228\n",
            "361447.54095890425\n",
            "1229\n",
            "361447.54095890425\n",
            "1230\n",
            "361447.54095890425\n",
            "1231\n",
            "361447.54095890425\n",
            "1232\n",
            "361447.54095890425\n",
            "1233\n",
            "361447.54095890425\n",
            "1234\n",
            "361447.54095890425\n",
            "1235\n",
            "361447.54095890425\n",
            "1236\n",
            "361447.54095890425\n",
            "1237\n",
            "361447.54095890425\n",
            "1238\n",
            "361447.54095890425\n",
            "1239\n",
            "361447.54095890425\n",
            "1240\n",
            "361447.54095890425\n",
            "1241\n",
            "361447.54095890425\n",
            "1242\n",
            "361447.54095890425\n",
            "1243\n",
            "361447.54095890425\n",
            "1244\n",
            "361447.54095890425\n",
            "1245\n",
            "361447.54095890425\n",
            "1246\n",
            "361447.54095890425\n",
            "1247\n",
            "361447.54095890425\n",
            "1248\n",
            "361447.54095890425\n",
            "1249\n",
            "361447.54095890425\n",
            "1250\n",
            "361447.54095890425\n",
            "1251\n",
            "361447.54095890425\n",
            "1252\n",
            "361447.54095890425\n",
            "1253\n",
            "361447.54095890425\n",
            "1254\n",
            "361447.54095890425\n",
            "1255\n",
            "361447.54095890425\n",
            "1256\n",
            "361447.54095890425\n",
            "1257\n",
            "361447.54095890425\n",
            "1258\n",
            "361447.54095890425\n",
            "1259\n",
            "361447.54095890425\n",
            "1260\n",
            "361447.54095890425\n",
            "1261\n",
            "361447.54095890425\n",
            "1262\n",
            "361447.54095890425\n",
            "1263\n",
            "361447.54095890425\n",
            "1264\n",
            "361447.54095890425\n",
            "1265\n",
            "361447.54095890425\n",
            "1266\n",
            "361447.54095890425\n",
            "1267\n",
            "361447.54095890425\n",
            "1268\n",
            "361447.54095890425\n",
            "1269\n",
            "361447.54095890425\n",
            "1270\n",
            "361447.54095890425\n",
            "1271\n",
            "361447.54095890425\n",
            "1272\n",
            "361447.54095890425\n",
            "1273\n",
            "361447.54095890425\n",
            "1274\n",
            "361447.54095890425\n",
            "1275\n",
            "361447.54095890425\n",
            "1276\n",
            "361447.54095890425\n",
            "1277\n",
            "361447.54095890425\n",
            "1278\n",
            "361447.54095890425\n",
            "1279\n",
            "361447.54095890425\n",
            "1280\n",
            "361447.54095890425\n",
            "1281\n",
            "361447.54095890425\n",
            "1282\n",
            "361447.54095890425\n",
            "1283\n",
            "361447.54095890425\n",
            "1284\n",
            "361447.54095890425\n",
            "1285\n",
            "361447.54095890425\n",
            "1286\n",
            "361447.54095890425\n",
            "1287\n",
            "361447.54095890425\n",
            "1288\n",
            "361447.54095890425\n",
            "1289\n",
            "361447.54095890425\n",
            "1290\n",
            "361447.54095890425\n",
            "1291\n",
            "361447.54095890425\n",
            "1292\n",
            "361447.54095890425\n",
            "1293\n",
            "361447.54095890425\n",
            "1294\n",
            "361447.54095890425\n",
            "1295\n",
            "361447.54095890425\n",
            "1296\n",
            "361447.54095890425\n",
            "1297\n",
            "361447.54095890425\n",
            "1298\n",
            "361447.54095890425\n",
            "1299\n",
            "361447.54095890425\n",
            "1300\n",
            "361447.54095890425\n",
            "1301\n",
            "361447.54095890425\n",
            "1302\n",
            "361447.54095890425\n",
            "1303\n",
            "361447.54095890425\n",
            "1304\n",
            "361447.54095890425\n",
            "1305\n",
            "361447.54095890425\n",
            "1306\n",
            "361447.54095890425\n",
            "1307\n",
            "361447.54095890425\n",
            "1308\n",
            "361447.54095890425\n",
            "1309\n",
            "361447.54095890425\n",
            "1310\n",
            "361447.54095890425\n",
            "1311\n",
            "361447.54095890425\n",
            "1312\n",
            "361447.54095890425\n",
            "1313\n",
            "361447.54095890425\n",
            "1314\n",
            "361447.54095890425\n",
            "1315\n",
            "361447.54095890425\n",
            "1316\n",
            "361447.54095890425\n",
            "1317\n",
            "361447.54095890425\n",
            "1318\n",
            "361447.54095890425\n",
            "1319\n",
            "361447.54095890425\n",
            "1320\n",
            "361447.54095890425\n",
            "1321\n",
            "361447.54095890425\n",
            "1322\n",
            "361447.54095890425\n",
            "1323\n",
            "361447.54095890425\n",
            "1324\n",
            "361447.54095890425\n",
            "1325\n",
            "361447.54095890425\n",
            "1326\n",
            "361447.54095890425\n",
            "1327\n",
            "361447.54095890425\n",
            "1328\n",
            "361447.54095890425\n",
            "1329\n",
            "361447.54095890425\n",
            "1330\n",
            "361447.54095890425\n",
            "1331\n",
            "361447.54095890425\n",
            "1332\n",
            "361447.54095890425\n",
            "1333\n",
            "361447.54095890425\n",
            "1334\n",
            "361447.54095890425\n",
            "1335\n",
            "361447.54095890425\n",
            "1336\n",
            "361447.54095890425\n",
            "1337\n",
            "361447.54095890425\n",
            "1338\n",
            "361447.54095890425\n",
            "1339\n",
            "361447.54095890425\n",
            "1340\n",
            "361447.54095890425\n",
            "1341\n",
            "361447.54095890425\n",
            "1342\n",
            "361447.54095890425\n",
            "1343\n",
            "361447.54095890425\n",
            "1344\n",
            "361447.54095890425\n",
            "1345\n",
            "361447.54095890425\n",
            "1346\n",
            "361447.54095890425\n",
            "1347\n",
            "361447.54095890425\n",
            "1348\n",
            "361447.54095890425\n",
            "1349\n",
            "361447.54095890425\n",
            "1350\n",
            "361447.54095890425\n",
            "1351\n",
            "361447.54095890425\n",
            "1352\n",
            "361447.54095890425\n",
            "1353\n",
            "361447.54095890425\n",
            "1354\n",
            "361447.54095890425\n",
            "1355\n",
            "361447.54095890425\n",
            "1356\n",
            "361447.54095890425\n",
            "1357\n",
            "361447.54095890425\n",
            "1358\n",
            "361447.54095890425\n",
            "1359\n",
            "361447.54095890425\n",
            "1360\n",
            "361447.54095890425\n",
            "1361\n",
            "361447.54095890425\n",
            "1362\n",
            "361447.54095890425\n",
            "1363\n",
            "361447.54095890425\n",
            "1364\n",
            "361447.54095890425\n",
            "1365\n",
            "361447.54095890425\n",
            "1366\n",
            "361447.54095890425\n",
            "1367\n",
            "361447.54095890425\n",
            "1368\n",
            "361447.54095890425\n",
            "1369\n",
            "361447.54095890425\n",
            "1370\n",
            "361447.54095890425\n",
            "1371\n",
            "361447.54095890425\n",
            "1372\n",
            "361447.54095890425\n",
            "1373\n",
            "361447.54095890425\n",
            "1374\n",
            "361447.54095890425\n",
            "1375\n",
            "361447.54095890425\n",
            "1376\n",
            "361447.54095890425\n",
            "1377\n",
            "361447.54095890425\n",
            "1378\n",
            "361447.54095890425\n",
            "1379\n",
            "361447.54095890425\n",
            "1380\n",
            "361447.54095890425\n",
            "1381\n",
            "361447.54095890425\n",
            "1382\n",
            "361447.54095890425\n",
            "1383\n",
            "361447.54095890425\n",
            "1384\n",
            "361447.54095890425\n",
            "1385\n",
            "361447.54095890425\n",
            "1386\n",
            "361447.54095890425\n",
            "1387\n",
            "361447.54095890425\n",
            "1388\n",
            "361447.54095890425\n",
            "1389\n",
            "361447.54095890425\n",
            "1390\n",
            "361447.54095890425\n",
            "1391\n",
            "361447.54095890425\n",
            "1392\n",
            "361447.54095890425\n",
            "1393\n",
            "361447.54095890425\n",
            "1394\n",
            "361447.54095890425\n",
            "1395\n",
            "361447.54095890425\n",
            "1396\n",
            "361447.54095890425\n",
            "1397\n",
            "361447.54095890425\n",
            "1398\n",
            "361447.54095890425\n",
            "1399\n",
            "361447.54095890425\n",
            "1400\n",
            "361447.54095890425\n",
            "1401\n",
            "361447.54095890425\n",
            "1402\n",
            "361447.54095890425\n",
            "1403\n",
            "361447.54095890425\n",
            "1404\n",
            "361447.54095890425\n",
            "1405\n",
            "361447.54095890425\n",
            "1406\n",
            "361447.54095890425\n",
            "1407\n",
            "361447.54095890425\n",
            "1408\n",
            "361447.54095890425\n",
            "1409\n",
            "361447.54095890425\n",
            "1410\n",
            "361447.54095890425\n",
            "1411\n",
            "361447.54095890425\n",
            "1412\n",
            "361447.54095890425\n",
            "1413\n",
            "361447.54095890425\n",
            "1414\n",
            "361447.54095890425\n",
            "1415\n",
            "361447.54095890425\n",
            "1416\n",
            "361447.54095890425\n",
            "1417\n",
            "361447.54095890425\n",
            "1418\n",
            "361447.54095890425\n",
            "1419\n",
            "361447.54095890425\n",
            "1420\n",
            "361447.54095890425\n",
            "1421\n",
            "361447.54095890425\n",
            "1422\n",
            "361447.54095890425\n",
            "1423\n",
            "361447.54095890425\n",
            "1424\n",
            "361447.54095890425\n",
            "1425\n",
            "361447.54095890425\n",
            "1426\n",
            "361447.54095890425\n",
            "1427\n",
            "361447.54095890425\n",
            "1428\n",
            "361447.54095890425\n",
            "1429\n",
            "361447.54095890425\n",
            "1430\n",
            "361447.54095890425\n",
            "1431\n",
            "361447.54095890425\n",
            "1432\n",
            "361447.54095890425\n",
            "1433\n",
            "361447.54095890425\n",
            "1434\n",
            "361447.54095890425\n",
            "1435\n",
            "361447.54095890425\n",
            "1436\n",
            "361447.54095890425\n",
            "1437\n",
            "361447.54095890425\n",
            "1438\n",
            "361447.54095890425\n",
            "1439\n",
            "361447.54095890425\n",
            "1440\n",
            "361447.54095890425\n",
            "1441\n",
            "361447.54095890425\n",
            "1442\n",
            "361447.54095890425\n",
            "1443\n",
            "361447.54095890425\n",
            "1444\n",
            "361447.54095890425\n",
            "1445\n",
            "361447.54095890425\n",
            "1446\n",
            "361447.54095890425\n",
            "1447\n",
            "361447.54095890425\n",
            "1448\n",
            "361447.54095890425\n",
            "1449\n",
            "361447.54095890425\n",
            "1450\n",
            "361447.54095890425\n",
            "1451\n",
            "361447.54095890425\n",
            "1452\n",
            "361447.54095890425\n",
            "1453\n",
            "361447.54095890425\n",
            "1454\n",
            "361447.54095890425\n",
            "1455\n",
            "361447.54095890425\n",
            "1456\n",
            "361447.54095890425\n",
            "1457\n",
            "361447.54095890425\n",
            "1458\n",
            "361447.54095890425\n",
            "1459\n",
            "361447.54095890425\n",
            "1460\n",
            "361447.54095890425\n",
            "1461\n",
            "361447.54095890425\n",
            "1462\n",
            "361447.54095890425\n",
            "1463\n",
            "361447.54095890425\n",
            "1464\n",
            "361447.54095890425\n",
            "1465\n",
            "361447.54095890425\n",
            "1466\n",
            "361447.54095890425\n",
            "1467\n",
            "361447.54095890425\n",
            "1468\n",
            "361447.54095890425\n",
            "1469\n",
            "361447.54095890425\n",
            "1470\n",
            "361447.54095890425\n",
            "1471\n",
            "361447.54095890425\n",
            "1472\n",
            "361447.54095890425\n",
            "1473\n",
            "361447.54095890425\n",
            "1474\n",
            "361447.54095890425\n",
            "1475\n",
            "361447.54095890425\n",
            "1476\n",
            "361447.54095890425\n",
            "1477\n",
            "361447.54095890425\n",
            "1478\n",
            "361447.54095890425\n",
            "1479\n",
            "361447.54095890425\n",
            "1480\n",
            "361447.54095890425\n",
            "1481\n",
            "361447.54095890425\n",
            "1482\n",
            "361447.54095890425\n",
            "1483\n",
            "361447.54095890425\n",
            "1484\n",
            "361447.54095890425\n",
            "1485\n",
            "361447.54095890425\n",
            "1486\n",
            "361447.54095890425\n",
            "1487\n",
            "361447.54095890425\n",
            "1488\n",
            "361447.54095890425\n",
            "1489\n",
            "361447.54095890425\n",
            "1490\n",
            "361447.54095890425\n",
            "1491\n",
            "361447.54095890425\n",
            "1492\n",
            "361447.54095890425\n",
            "1493\n",
            "361447.54095890425\n",
            "1494\n",
            "361447.54095890425\n",
            "1495\n",
            "361447.54095890425\n",
            "1496\n",
            "361447.54095890425\n",
            "1497\n",
            "361447.54095890425\n",
            "1498\n",
            "361447.54095890425\n",
            "1499\n",
            "361447.54095890425\n",
            "1500\n",
            "361447.54095890425\n",
            "1501\n",
            "361447.54095890425\n",
            "1502\n",
            "361447.54095890425\n",
            "1503\n",
            "361447.54095890425\n",
            "1504\n",
            "361447.54095890425\n",
            "1505\n",
            "361447.54095890425\n",
            "1506\n",
            "361447.54095890425\n",
            "1507\n",
            "361447.54095890425\n",
            "1508\n",
            "361447.54095890425\n",
            "1509\n",
            "361447.54095890425\n",
            "1510\n",
            "361447.54095890425\n",
            "1511\n",
            "361447.54095890425\n",
            "1512\n",
            "361447.54095890425\n",
            "1513\n",
            "361447.54095890425\n",
            "1514\n",
            "361447.54095890425\n",
            "1515\n",
            "361447.54095890425\n",
            "1516\n",
            "361447.54095890425\n",
            "1517\n",
            "361447.54095890425\n",
            "1518\n",
            "361447.54095890425\n",
            "1519\n",
            "361447.54095890425\n",
            "1520\n",
            "361447.54095890425\n",
            "1521\n",
            "361447.54095890425\n",
            "1522\n",
            "361447.54095890425\n",
            "1523\n",
            "361447.54095890425\n",
            "1524\n",
            "361447.54095890425\n",
            "1525\n",
            "361447.54095890425\n",
            "1526\n",
            "361447.54095890425\n",
            "1527\n",
            "361447.54095890425\n",
            "1528\n",
            "361447.54095890425\n",
            "1529\n",
            "361447.54095890425\n",
            "1530\n",
            "361447.54095890425\n",
            "1531\n",
            "361447.54095890425\n",
            "1532\n",
            "361447.54095890425\n",
            "1533\n",
            "361447.54095890425\n",
            "1534\n",
            "361447.54095890425\n",
            "1535\n",
            "361447.54095890425\n",
            "1536\n",
            "361447.54095890425\n",
            "1537\n",
            "361447.54095890425\n",
            "1538\n",
            "361447.54095890425\n",
            "1539\n",
            "361447.54095890425\n",
            "1540\n",
            "361447.54095890425\n",
            "1541\n",
            "361447.54095890425\n",
            "1542\n",
            "361447.54095890425\n",
            "1543\n",
            "361447.54095890425\n",
            "1544\n",
            "361447.54095890425\n",
            "1545\n",
            "361447.54095890425\n",
            "1546\n",
            "361447.54095890425\n",
            "1547\n",
            "361447.54095890425\n",
            "1548\n",
            "361447.54095890425\n",
            "1549\n",
            "361447.54095890425\n",
            "1550\n",
            "361447.54095890425\n",
            "1551\n",
            "361447.54095890425\n",
            "1552\n",
            "361447.54095890425\n",
            "1553\n",
            "361447.54095890425\n",
            "1554\n",
            "361447.54095890425\n",
            "1555\n",
            "361447.54095890425\n",
            "1556\n",
            "361447.54095890425\n",
            "1557\n",
            "361447.54095890425\n",
            "1558\n",
            "361447.54095890425\n",
            "1559\n",
            "361447.54095890425\n",
            "1560\n",
            "361447.54095890425\n",
            "1561\n",
            "361447.54095890425\n",
            "1562\n",
            "361447.54095890425\n",
            "1563\n",
            "361447.54095890425\n",
            "1564\n",
            "361447.54095890425\n",
            "1565\n",
            "361447.54095890425\n",
            "1566\n",
            "361447.54095890425\n",
            "1567\n",
            "361447.54095890425\n",
            "1568\n",
            "361447.54095890425\n",
            "1569\n",
            "361447.54095890425\n",
            "1570\n",
            "361447.54095890425\n",
            "1571\n",
            "361447.54095890425\n",
            "1572\n",
            "361447.54095890425\n",
            "1573\n",
            "361447.54095890425\n",
            "1574\n",
            "361447.54095890425\n",
            "1575\n",
            "361447.54095890425\n",
            "1576\n",
            "361447.54095890425\n",
            "1577\n",
            "361447.54095890425\n",
            "1578\n",
            "361447.54095890425\n",
            "1579\n",
            "361447.54095890425\n",
            "1580\n",
            "361447.54095890425\n",
            "1581\n",
            "361447.54095890425\n",
            "1582\n",
            "361447.54095890425\n",
            "1583\n",
            "361447.54095890425\n",
            "1584\n",
            "361447.54095890425\n",
            "1585\n",
            "361447.54095890425\n",
            "1586\n",
            "361447.54095890425\n",
            "1587\n",
            "361447.54095890425\n",
            "1588\n",
            "361447.54095890425\n",
            "1589\n",
            "361447.54095890425\n",
            "1590\n",
            "361447.54095890425\n",
            "1591\n",
            "361447.54095890425\n",
            "1592\n",
            "361447.54095890425\n",
            "1593\n",
            "361447.54095890425\n",
            "1594\n",
            "361447.54095890425\n",
            "1595\n",
            "361447.54095890425\n",
            "1596\n",
            "361447.54095890425\n",
            "1597\n",
            "361447.54095890425\n",
            "1598\n",
            "361447.54095890425\n",
            "1599\n",
            "361447.54095890425\n",
            "1600\n",
            "361447.54095890425\n",
            "1601\n",
            "361447.54095890425\n",
            "1602\n",
            "361447.54095890425\n",
            "1603\n",
            "361447.54095890425\n",
            "1604\n",
            "361447.54095890425\n",
            "1605\n",
            "361447.54095890425\n",
            "1606\n",
            "361447.54095890425\n",
            "1607\n",
            "361447.54095890425\n",
            "1608\n",
            "361447.54095890425\n",
            "1609\n",
            "361447.54095890425\n",
            "1610\n",
            "361447.54095890425\n",
            "1611\n",
            "361447.54095890425\n",
            "1612\n",
            "361447.54095890425\n",
            "1613\n",
            "361447.54095890425\n",
            "1614\n",
            "361447.54095890425\n",
            "1615\n",
            "361447.54095890425\n",
            "1616\n",
            "361447.54095890425\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JivWKbnZHY1D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "df993c74-6b0b-4a15-c321-23ce75a9327a"
      },
      "source": [
        "# Make a copy of the matrix to use in this notebook\n",
        "cmatrices = np.array(cmatrices)\n",
        "cmatrices_copy = cmatrices.copy()"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-150-281ec0aceaec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcmatrices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmatrices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcmatrices_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcmatrices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'cmatrices' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pai4-hPKH_9i",
        "colab_type": "text"
      },
      "source": [
        "## Find the indices of datapoints which have a Coulomb element of more than 1000 (probably due to a glitch in the MM94 optimization) and remove these from our dataset. Also, remove datapoints which have binding affinity of 0 (log of 0= -infinity, not good...)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0Dq01VkF1iC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "idx_to_remove = np.where(cmatrices_copy > 1000)[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHwvmf7kF1mx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "1ac885dd-a233-40a9-8e23-aef793f0f0cd"
      },
      "source": [
        "idx_to_remove"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  80,  133,  133,  147,  147,  148,  148,  151,  151,  151,  151,\n",
              "        156,  188,  252,  265,  265,  284,  300,  393,  393,  401,  401,\n",
              "        402,  402,  403,  425,  438,  484,  548,  548,  548,  548,  562,\n",
              "        562,  562,  562,  562,  562,  563,  563,  613,  643,  643,  679,\n",
              "        679,  680,  680,  707,  716,  789,  861,  862,  894,  894,  894,\n",
              "        894,  917,  975,  994,  994,  994,  994,  994,  994,  994,  994,\n",
              "       1074, 1209, 1224, 1257, 1292, 1321, 1323, 1324, 1346, 1347, 1352,\n",
              "       1392, 1392, 1504, 1512, 1545, 1548, 1548])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2J1lVFHQF1qL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ec7ceb83-2313-4f9f-e9b6-ec3a41b9035a"
      },
      "source": [
        "## Remove these glitchy datapoints\n",
        "cmatrices_copy = np.delete(cmatrices_copy, idx_to_remove, axis = 0); cmatrices_copy.shape"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1566, 122, 122)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HN5peLjAIk2V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ca33b504-4853-4278-ad61-a7ea13a0a5e7"
      },
      "source": [
        "# Check where our MM94 optimization completely failed\n",
        "# to even generate a conformer\n",
        "\n",
        "failed_indices"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[559]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZlGhDwMIn2m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dropping these failed indices\n",
        "\n",
        "affinity_train_test = affinity_train_test.drop(affinity_train_test.index[failed_indices])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xZfjV80Iq28",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dropping datapoints that had too large Coulomb values\n",
        "\n",
        "affinity_train_test = affinity_train_test.drop(affinity_train_test.index[idx_to_remove])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yL-vulPJha4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "06773aaa-f6d2-4bd2-db75-1b549e800091"
      },
      "source": [
        "affinity_train_test.shape"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1566,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Une1ZfRQIF2k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c463c92f-4a7c-4a62-bbc5-ea253f05e263"
      },
      "source": [
        "# Check shape of our data matrix\n",
        "cmatrices_copy.shape"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1566, 122, 122)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0ijz_0uuke2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "3ec5017e-d0e4-4e16-dce3-c0025b37449d"
      },
      "source": [
        "# Checking that there are no 0 values in our\n",
        "# y_labels series\n",
        "\n",
        "# Need to remove this value!!\n",
        "\n",
        "affinity_train_test[affinity_train_test < 0.1]\n",
        "\n"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "885     0.000\n",
              "1831    0.023\n",
              "2209    0.080\n",
              "2511    0.040\n",
              "Name: Standard Value, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlmykAH2uki6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "afa40aa9-f65a-48dd-bdb1-d57195e2da4e"
      },
      "source": [
        "# Some (sort of) hacky code to get rid of the weird drug from our dataset\n",
        "idx_to_drop = np.where(affinity_train_test.index==885)[0]; idx_to_drop\n",
        "affinity_train_test = affinity_train_test.drop(885)\n",
        "cmatrices_copy = np.delete(cmatrices_copy, idx_to_drop, axis = 0)\n",
        "cmatrices_copy.shape"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1565, 122, 122)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6edhXmCa8T1w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7ee64608-3e53-45ef-dcbc-f49ec3d88f18"
      },
      "source": [
        "affinity_train_test.shape"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1565,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnRA-GMQU-pk",
        "colab_type": "text"
      },
      "source": [
        "## Convert binding affinity to the natural logarithm of binding affinity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wo0o3Xkqsc6q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We will try to predict the log binding affinity.\n",
        "# This is more natural to do in the context of drug binding.\n",
        "\n",
        "log_affinity_train_test = np.log(affinity_train_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiXrWllwVPnA",
        "colab_type": "text"
      },
      "source": [
        "## Have a look at our final datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbNtMB8dVQGJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b9bfbf8a-2ded-455c-edf4-4acd97c05e19"
      },
      "source": [
        "# X data is cmatrices_copy\n",
        "# y data is log_affinity_train_test\n",
        "cmatrices_copy.shape, log_affinity_train_test.shape"
      ],
      "execution_count": 235,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1565, 122, 122), (1565,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 235
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLZx_BItWyQF",
        "colab_type": "text"
      },
      "source": [
        "## Let's look at the distribution of log(binding affinities) for the drugs in this dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpE9nW-3ucVt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "outputId": "a4b8e1f1-7fcb-46d4-8087-0e76ac136ffc"
      },
      "source": [
        "# Let's take a look at our distribution of \n",
        "import matplotlib.pyplot as plt\n",
        "plt.hist(log_affinity_train_test)"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([  8.,  10.,  35., 135., 161., 298., 356., 355., 152.,  55.]),\n",
              " array([-3.77226106, -2.14933642, -0.52641178,  1.09651286,  2.71943751,\n",
              "         4.34236215,  5.96528679,  7.58821143,  9.21113608, 10.83406072,\n",
              "        12.45698536]),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 161
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngNcAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEjtl7-iYNRa",
        "colab_type": "text"
      },
      "source": [
        "## This looks like it's going to be a fairly hard dataset to separate..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTdbFa4JMXFN",
        "colab_type": "text"
      },
      "source": [
        "## Split the dataset into training and testing sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "V6IwdJ97YwkH",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(cmatrices_copy, np.array(log_affinity_train_test), random_state = 101)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnLTc_ytbFFb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8gaCOjfx5Dw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0718cbcb-a058-4beb-ca84-1550172a663a"
      },
      "source": [
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1173, 122, 122), (392, 122, 122), (1173,), (392,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKmHTA7zgPKZ",
        "colab_type": "text"
      },
      "source": [
        "# Converting the Coulomb matrix into a more suitable input for a neural network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kafb2LogbBW",
        "colab_type": "text"
      },
      "source": [
        "##Three problems with the Coulomb matrix are the follows:\n",
        "1. The size of the Coulomb matrix is equal to the number of atoms in the molecule. Therefore different molecules will have differently sized Coulomb matrices, which is a less-than-ideal data input.\n",
        "2.  For one molecule with N atoms, there exists N! possible valid Coulomb matrices, as the molecule is invariant to atom index labelling, but each different set of labels (for which there are N! of them) correspond to a different Coulomb matrix.\n",
        "3.  A lot of label-relevant information is contained in the ordering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyyVOrlQhgBO",
        "colab_type": "text"
      },
      "source": [
        "##1.  The first of these issues can be sorted with ***padding***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkJzBvZzhpqF",
        "colab_type": "text"
      },
      "source": [
        "We take the biggest molecule in our dataset (the one with the most atoms) and simply set the size of all our matrices to that atom. Then, we fill in the matrices of the smaller molecules in the upper left of the big matrix - the rest of the entries are padded with zeros."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WckN465Ly4A",
        "colab_type": "text"
      },
      "source": [
        "![padding_method](https://i.ibb.co/TLTWR1Q/Coulomb-Net-slides-4.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVTEMyJ2PCxy",
        "colab_type": "text"
      },
      "source": [
        "##2. The *second* of these issues can be partly negated by sorting the Coulomb matrix essentially by atom weights (in fact, we sort by the row-norm of the matrix, but it's close enough to sorting by atom weights).\n",
        "\n",
        "## However, there is a catch - when we sort, we add some noise to the matrix, so that the order of each matrix is not exactly the same. This exposes the neural network to slight variations of the Coulomb matrix in each training batch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8AbJA1n1QEhK",
        "colab_type": "text"
      },
      "source": [
        "![sorting_algo](https://i.ibb.co/zFCLQF9/Screenshot-2019-08-05-at-15-47-39.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAVbUldyQown",
        "colab_type": "text"
      },
      "source": [
        "##3. To work around this problem, we encode the Coulomb matrix at the end into a binary input, the code of which is below. Here is an extract from the original paper for how it is done:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgzsvB47Q20z",
        "colab_type": "text"
      },
      "source": [
        "![tanh_input](https://i.ibb.co/K0RwgBC/Screenshot-2019-08-05-at-15-52-00.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vmsj0CVBL-D0",
        "colab_type": "text"
      },
      "source": [
        "## Define some input preprocessing functions to tackle the above problems"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJQIhxEHME3Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Module:\n",
        "  def update(self, lr):pass\n",
        "  def average(self,nn,a):pass\n",
        "  def backward(self,DY):pass\n",
        "  def forward(self,X):pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCR1FJCaNUfC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Input(Module):\n",
        "  \n",
        "  def __init__(self,X):\n",
        "    self.step=1.0\n",
        "    self.noise=1.0\n",
        "    \n",
        "    # Boolean array to select for only the upper triangular half of the matrix.\n",
        "    # Since the matrix is symmetric, the lower triangular half is exactly the same\n",
        "    # as the upper triangular half, hence redundant information.\n",
        "    \n",
        "    self.triuind = (np.arange(122)[:,np.newaxis] <= np.arange(122)[np.newaxis,:]).flatten()\n",
        "    \n",
        "    # Get the maximum value of the X array - this will be required to generate\n",
        "    # the binary inputs to our neural network\n",
        "    self.max = 0\n",
        "    for _ in range(10): \n",
        "      self.max=np.maximum(self.max,self.realize(X).max(axis=0))\n",
        "      \n",
        "    # Obtain some normalization metrics about the dataset\n",
        "    X = self.expand(self.realize(X))\n",
        "    self.nbout = X.shape[1]\n",
        "    self.mean = X.mean(axis=0)\n",
        "    self.std = (X - self.mean).std()\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "  def realize(self,X):\n",
        "    '''\n",
        "    Function to sort the Coulomb matrix (with some random noise)\n",
        "    '''\n",
        "    def _realize_(x):\n",
        "      inds = np.argsort(-(x**2).sum(axis=0)**.5+np.random.normal(0,self.noise,x[0].shape))\n",
        "      x = x[inds,:][:,inds]*1\n",
        "      x = x.flatten()[self.triuind]\n",
        "      return x\n",
        "    return np.array([_realize_(z) for z in X])\n",
        "      \n",
        "    \n",
        "  def expand(self,X):\n",
        "    '''\n",
        "    Function to expand the Coulomb matrix into a set of (essentially) binary inputs\n",
        "    '''\n",
        "    Xexp = []\n",
        "    for i in range(X.shape[1]):\n",
        "      for k in np.arange(0,self.max[i]+self.step,self.step):\n",
        "        Xexp += [np.tanh((X[:,i]-k)/self.step)]\n",
        "    return np.array(Xexp).T\n",
        "  \n",
        "  \n",
        "  def normalize(self,X): return (X-self.mean)/self.std\n",
        "  \n",
        "  def forward(self,X): return self.normalize(self.expand(self.realize(X))).astype('float32')\n",
        "\n",
        "  \n",
        "  \n",
        "class Output(Module):\n",
        "  \n",
        "  def __init__(self,T):\n",
        "    self.tmean = T.mean()\n",
        "    self.tstd = T.std()\n",
        "    self.nbinp = 1\n",
        "    \n",
        "  def forward(self,X):\n",
        "    return X*self.tstd + self.tmean"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ck9_9EWFZAoR",
        "colab_type": "text"
      },
      "source": [
        "# Tensorflow time..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdPtjWwuRQgY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7W89y1XgY_zA",
        "colab_type": "text"
      },
      "source": [
        "## Define some helper functions to shuffle the training data, as well as get the next batch of training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Q8UggBbbMoO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def randomize(x,y):\n",
        "  '''\n",
        "  Randomizes the order of data samples and corresponding labels\n",
        "  '''\n",
        "  perm = np.random.permutation(y.shape[0])\n",
        "  shuffled_x = x[perm]\n",
        "  shuffled_y = y[perm]\n",
        "  return shuffled_x, shuffled_y\n",
        "def get_next_batch(x,y,start,end):\n",
        "  '''\n",
        "  Gets the next batch of training data\n",
        "  '''\n",
        "  x_batch = x[start:end]\n",
        "  y_batch = y[start:end]\n",
        "  return x_batch, y_batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsLNeL15ZNrq",
        "colab_type": "text"
      },
      "source": [
        "## Define two helper functions to help us initalize the weights with [Xavier initialization](http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2j_XSv1Y9KD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def weight_variable(name, shape):\n",
        "  initer = tf.truncated_normal_initializer(stddev=(1/(shape[0])**.5))\n",
        "  return tf.get_variable('W_'+name,\n",
        "                        dtype=tf.float32,\n",
        "                        shape=shape,\n",
        "                        initializer=initer)\n",
        "\n",
        "def bias_variable(name,shape):\n",
        "  initial = tf.constant(0.,shape=shape,dtype=tf.float32)\n",
        "  return tf.get_variable('b_'+name,\n",
        "                        dtype=tf.float32,\n",
        "                        initializer=initial)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbvGFOsAZVQ1",
        "colab_type": "text"
      },
      "source": [
        "## Define a helper function to forward propogate an input through a fully connected neural network layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvGgO99hZTcB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fc_layer(x,num_units,name,use_sigmoid=True):\n",
        "  in_dim=x.get_shape().as_list()[1]\n",
        "  W=weight_variable(name,shape=[in_dim,num_units])\n",
        "  b=bias_variable(name,[num_units])\n",
        "  layer=tf.matmul(x,W)\n",
        "  layer+=b\n",
        "  if use_sigmoid:\n",
        "    layer=tf.nn.tanh(layer)\n",
        "  return layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "652fRTAPNYWW",
        "colab_type": "text"
      },
      "source": [
        "## Apply the preprocessing to the training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpii4x38Zgdb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "I,O = Input(X_train),Output(y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yF3apttWZj-P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b06085ff-0fc3-4ae9-f7ad-2f224856be6a"
      },
      "source": [
        "# The dimensionality of our flattened, binarized Coulomb matrix\n",
        "I.nbout"
      ],
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "95944"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtsrBFTZNlp3",
        "colab_type": "text"
      },
      "source": [
        "## Hyperparameters of the NN (lots of untested scope for improvement here)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVJ5HBl1Nnu8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hyper-parameters\n",
        "epochs = 1000             # Total number of training epochs\n",
        "batch_size = 25        # Training batch size\n",
        "display_freq = 20      # Frequency of displaying the training results\n",
        "learning_rate = 0.0001   # The optimization initial learning rate\n",
        " \n",
        "  \n",
        "flattened_input_size = I.nbout\n",
        "n_classes = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYtA15ZTSsYj",
        "colab_type": "text"
      },
      "source": [
        "## Architecture: ***2 hidden layers, 100 nodes in each layer*** (pretty simple architechture, but does a good job. Need to experiment with this a bit more)\n",
        "\n",
        "![arch](https://cdn.semrush.com/blog/static/media/11/25/112519bb26b32f29644e30123d8525f5/neural-network.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTIflIvLNs9b",
        "colab_type": "text"
      },
      "source": [
        "## Reset the graph, define variables and the computational graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOs52gwnbMyV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.reset_default_graph()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXLJ7YzbVRJB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = tf.placeholder(tf.float32,shape=[None,flattened_input_size],name='X')\n",
        "y = tf.placeholder(tf.float32,shape=[None,n_classes],name='Y')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_jK2USiVozy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Computational Graph\n",
        "\n",
        "fc1 = fc_layer(x,400,'FC1',use_sigmoid=True)\n",
        "fc2 = fc_layer(fc1,100,'FC2',use_sigmoid=True)\n",
        "pre_preds = fc_layer(fc2,n_classes,'OUT',use_sigmoid=False)\n",
        "preds = O.forward(pre_preds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLWL1DlhNy2q",
        "colab_type": "text"
      },
      "source": [
        "## Define the loss function and optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0p6gvUkWfxk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loss function and optimizer\n",
        "\n",
        "loss = tf.losses.mean_squared_error(labels=y,predictions=preds)\n",
        "\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate,name='Adam-op').minimize(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQELScUROBQH",
        "colab_type": "text"
      },
      "source": [
        "## Make a new folder to store the model weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XBEcZPfOD76",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir /content/tmp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2gQ2AxaOLrx",
        "colab_type": "text"
      },
      "source": [
        "## Initialize the variables, the saver, and GPU options"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xw3sdg6eXEYl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "init=tf.global_variables_initializer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlhCCsaxB-sw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "saver = tf.train.Saver()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKf_sudpLAzr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khrs72N-OUIH",
        "colab_type": "text"
      },
      "source": [
        "# Start training the model!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AhwcyQ3YfSc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5b25ee7d-ff1f-426e-c9b1-313e18356dc4"
      },
      "source": [
        "sess = tf.InteractiveSession(config = config)\n",
        "sess.run(init)\n",
        "global_step=0\n",
        "\n",
        "if os.path.exists('/content/tmp/checkpoint'):\n",
        "  print('\\nRestoring model...\\n')\n",
        "  saver.restore(sess, '/content/tmp/model.ckpt')\n",
        "else:\n",
        "  print('\\nCreating a saver to save the model weights\\n')\n",
        "  saver = tf.train.Saver()\n",
        "\n",
        "num_tr_iter = int(len(X_test) / batch_size)\n",
        "\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  print('Training epoch:{}'.format(epoch+1))\n",
        "  \n",
        "  X_train, y_train = randomize(X_train,y_train)\n",
        "  \n",
        "  for iteration in trange(num_tr_iter):\n",
        "    global_step+=1\n",
        "    \n",
        "    start = iteration*batch_size\n",
        "    end = (iteration+1)*batch_size\n",
        "    \n",
        "    x_batch, y_batch = get_next_batch(X_train,y_train,start,end)\n",
        "    \n",
        "    x_batch = I.forward(x_batch)\n",
        "    \n",
        "    y_batch = y_batch[:,np.newaxis]\n",
        "    \n",
        "    # Run optimization operation\n",
        "    feed_dict_batch = {x:x_batch, y:y_batch}\n",
        "    sess.run(optimizer,feed_dict=feed_dict_batch)\n",
        "    \n",
        "\n",
        "  # Calc and display batch loss\n",
        "  loss_batch = sess.run(loss,feed_dict={x:x_batch,y:y_batch})\n",
        "  print(\"iter {0:3d}:\\t Training Loss={1:.2f}\".\n",
        "        format(iteration, loss_batch))\n",
        "            \n",
        "  # Calc and display validation loss \n",
        "  test_input = I.forward(X_test)\n",
        "  val_loss_batch = sess.run(loss, feed_dict={x:test_input, y:y_test[:,np.newaxis]})\n",
        "  print(\"iter {0:3d}:\\t Validation loss={1:.2f}\".format(iteration,\n",
        "                                                       val_loss_batch))\n",
        "      \n",
        "  # Save the model every epoch\n",
        "  save_path = saver.save(sess, \"/content/tmp/model.ckpt\")\n",
        "  print(\"Model saved in path: %s\" % save_path)"
      ],
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/15 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Creating a saver to save the model weights\n",
            "\n",
            "Training epoch:1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 15/15 [00:10<00:00,  1.40it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "iter  14:\t Training Loss=6.78\n",
            "iter  14:\t Validation loss=10.29\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/15 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model saved in path: /content/tmp/model.ckpt\n",
            "Training epoch:2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 15/15 [00:10<00:00,  1.41it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "iter  14:\t Training Loss=7.42\n",
            "iter  14:\t Validation loss=7.08\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/15 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model saved in path: /content/tmp/model.ckpt\n",
            "Training epoch:3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 15/15 [00:10<00:00,  1.40it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "iter  14:\t Training Loss=4.81\n",
            "iter  14:\t Validation loss=6.25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/15 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model saved in path: /content/tmp/model.ckpt\n",
            "Training epoch:4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 15/15 [00:10<00:00,  1.44it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "iter  14:\t Training Loss=6.95\n",
            "iter  14:\t Validation loss=6.17\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/15 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model saved in path: /content/tmp/model.ckpt\n",
            "Training epoch:5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 15/15 [00:10<00:00,  1.44it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "iter  14:\t Training Loss=3.60\n",
            "iter  14:\t Validation loss=5.90\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/15 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model saved in path: /content/tmp/model.ckpt\n",
            "Training epoch:6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 15/15 [00:10<00:00,  1.43it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "iter  14:\t Training Loss=2.44\n",
            "iter  14:\t Validation loss=5.89\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/15 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model saved in path: /content/tmp/model.ckpt\n",
            "Training epoch:7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 15/15 [00:10<00:00,  1.45it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "iter  14:\t Training Loss=4.13\n",
            "iter  14:\t Validation loss=5.59\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/15 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model saved in path: /content/tmp/model.ckpt\n",
            "Training epoch:8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 15/15 [00:10<00:00,  1.45it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "iter  14:\t Training Loss=3.72\n",
            "iter  14:\t Validation loss=5.39\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/15 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model saved in path: /content/tmp/model.ckpt\n",
            "Training epoch:9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 47%|████▋     | 7/15 [00:04<00:05,  1.45it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-217-37c2eb52f3cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mx_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mI\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-145-963b7b198461>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     33\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrealize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-145-963b7b198461>\u001b[0m in \u001b[0;36mexpand\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mXexp\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXexp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiBZgqtaSx11",
        "colab_type": "text"
      },
      "source": [
        "#See some of the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tU2z0ZyAb4Bw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "00ef3b1a-326b-4885-e68c-9419546a8c2c"
      },
      "source": [
        "modxtest = I.forward(X_test)\n",
        "modytest = y_test.copy()[:,np.newaxis]\n",
        "print(modxtest.shape,modytest.shape)\n",
        "feed_dict_test = {x: modxtest, y:modytest}\n",
        "predictions = sess.run(preds, feed_dict = feed_dict_test)"
      ],
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(392, 95944) (392, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMSytNAqdhPq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "03f67d58-9283-4414-e02c-bdbf9010dde1"
      },
      "source": [
        "import pandas as pd\n",
        "results_df = pd.DataFrame(np.array([predictions.reshape(-1),modytest.reshape(-1)]).T, columns = ['predictions','true']); results_df"
      ],
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>predictions</th>\n",
              "      <th>true</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.307949</td>\n",
              "      <td>4.065602</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.199729</td>\n",
              "      <td>9.239899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6.648564</td>\n",
              "      <td>5.010635</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.925185</td>\n",
              "      <td>2.532903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6.224054</td>\n",
              "      <td>4.143135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5.786320</td>\n",
              "      <td>4.442651</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>8.735395</td>\n",
              "      <td>9.392662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>6.068913</td>\n",
              "      <td>3.850148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>6.468623</td>\n",
              "      <td>2.397895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>5.163790</td>\n",
              "      <td>8.328934</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>7.298910</td>\n",
              "      <td>7.863267</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>7.084153</td>\n",
              "      <td>7.495542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>5.460505</td>\n",
              "      <td>5.799093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>7.299791</td>\n",
              "      <td>5.010635</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>6.078752</td>\n",
              "      <td>7.244228</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>9.640970</td>\n",
              "      <td>6.907755</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>7.055809</td>\n",
              "      <td>9.210340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>8.409899</td>\n",
              "      <td>10.545341</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>5.236543</td>\n",
              "      <td>6.907755</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>7.853885</td>\n",
              "      <td>7.691200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>6.577185</td>\n",
              "      <td>6.593045</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>7.740009</td>\n",
              "      <td>5.703782</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>6.248491</td>\n",
              "      <td>5.828946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>9.216809</td>\n",
              "      <td>11.156251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>7.669116</td>\n",
              "      <td>4.234107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>6.674841</td>\n",
              "      <td>2.532903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>7.737313</td>\n",
              "      <td>7.138017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>6.932031</td>\n",
              "      <td>5.247024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>3.026953</td>\n",
              "      <td>3.258097</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>7.791214</td>\n",
              "      <td>8.732305</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>362</th>\n",
              "      <td>9.177060</td>\n",
              "      <td>9.392662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>363</th>\n",
              "      <td>4.990319</td>\n",
              "      <td>5.629059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>364</th>\n",
              "      <td>5.757910</td>\n",
              "      <td>9.903488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>365</th>\n",
              "      <td>4.945631</td>\n",
              "      <td>2.564949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>366</th>\n",
              "      <td>5.813056</td>\n",
              "      <td>6.907755</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>367</th>\n",
              "      <td>5.494741</td>\n",
              "      <td>7.438384</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>368</th>\n",
              "      <td>6.903078</td>\n",
              "      <td>4.867534</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>369</th>\n",
              "      <td>7.385701</td>\n",
              "      <td>6.870469</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>370</th>\n",
              "      <td>5.972128</td>\n",
              "      <td>6.257668</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>371</th>\n",
              "      <td>7.879028</td>\n",
              "      <td>7.170120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>372</th>\n",
              "      <td>5.825750</td>\n",
              "      <td>4.605170</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>373</th>\n",
              "      <td>8.979359</td>\n",
              "      <td>9.903488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>374</th>\n",
              "      <td>4.647740</td>\n",
              "      <td>1.740466</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>375</th>\n",
              "      <td>5.590145</td>\n",
              "      <td>10.308953</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>376</th>\n",
              "      <td>6.214162</td>\n",
              "      <td>12.400817</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>377</th>\n",
              "      <td>3.426888</td>\n",
              "      <td>1.808289</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>378</th>\n",
              "      <td>5.717722</td>\n",
              "      <td>4.605170</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>379</th>\n",
              "      <td>4.866982</td>\n",
              "      <td>2.708050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>380</th>\n",
              "      <td>5.415040</td>\n",
              "      <td>6.907755</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>381</th>\n",
              "      <td>6.705650</td>\n",
              "      <td>8.517193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>382</th>\n",
              "      <td>7.995681</td>\n",
              "      <td>8.779557</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>383</th>\n",
              "      <td>7.355734</td>\n",
              "      <td>5.828946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>384</th>\n",
              "      <td>9.607982</td>\n",
              "      <td>9.047821</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>385</th>\n",
              "      <td>6.521163</td>\n",
              "      <td>7.828791</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>386</th>\n",
              "      <td>5.934394</td>\n",
              "      <td>6.821107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>387</th>\n",
              "      <td>7.020532</td>\n",
              "      <td>3.828641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>388</th>\n",
              "      <td>7.882883</td>\n",
              "      <td>7.090077</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>389</th>\n",
              "      <td>8.234948</td>\n",
              "      <td>9.903488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>390</th>\n",
              "      <td>8.866275</td>\n",
              "      <td>9.210340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>391</th>\n",
              "      <td>6.762305</td>\n",
              "      <td>3.496508</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>392 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     predictions       true\n",
              "0       7.307949   4.065602\n",
              "1       7.199729   9.239899\n",
              "2       6.648564   5.010635\n",
              "3       4.925185   2.532903\n",
              "4       6.224054   4.143135\n",
              "5       5.786320   4.442651\n",
              "6       8.735395   9.392662\n",
              "7       6.068913   3.850148\n",
              "8       6.468623   2.397895\n",
              "9       5.163790   8.328934\n",
              "10      7.298910   7.863267\n",
              "11      7.084153   7.495542\n",
              "12      5.460505   5.799093\n",
              "13      7.299791   5.010635\n",
              "14      6.078752   7.244228\n",
              "15      9.640970   6.907755\n",
              "16      7.055809   9.210340\n",
              "17      8.409899  10.545341\n",
              "18      5.236543   6.907755\n",
              "19      7.853885   7.691200\n",
              "20      6.577185   6.593045\n",
              "21      7.740009   5.703782\n",
              "22      6.248491   5.828946\n",
              "23      9.216809  11.156251\n",
              "24      7.669116   4.234107\n",
              "25      6.674841   2.532903\n",
              "26      7.737313   7.138017\n",
              "27      6.932031   5.247024\n",
              "28      3.026953   3.258097\n",
              "29      7.791214   8.732305\n",
              "..           ...        ...\n",
              "362     9.177060   9.392662\n",
              "363     4.990319   5.629059\n",
              "364     5.757910   9.903488\n",
              "365     4.945631   2.564949\n",
              "366     5.813056   6.907755\n",
              "367     5.494741   7.438384\n",
              "368     6.903078   4.867534\n",
              "369     7.385701   6.870469\n",
              "370     5.972128   6.257668\n",
              "371     7.879028   7.170120\n",
              "372     5.825750   4.605170\n",
              "373     8.979359   9.903488\n",
              "374     4.647740   1.740466\n",
              "375     5.590145  10.308953\n",
              "376     6.214162  12.400817\n",
              "377     3.426888   1.808289\n",
              "378     5.717722   4.605170\n",
              "379     4.866982   2.708050\n",
              "380     5.415040   6.907755\n",
              "381     6.705650   8.517193\n",
              "382     7.995681   8.779557\n",
              "383     7.355734   5.828946\n",
              "384     9.607982   9.047821\n",
              "385     6.521163   7.828791\n",
              "386     5.934394   6.821107\n",
              "387     7.020532   3.828641\n",
              "388     7.882883   7.090077\n",
              "389     8.234948   9.903488\n",
              "390     8.866275   9.210340\n",
              "391     6.762305   3.496508\n",
              "\n",
              "[392 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 221
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8FQFp4A3E2Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds_array = np.array(results_df['predictions'])\n",
        "true_array = np.array(results_df['true'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtycavI4S7kd",
        "colab_type": "text"
      },
      "source": [
        "## Convert to binary classification problem - see how it did"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tk6Ke6Cb4Z6K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "0e166453-782d-4749-e332-9662b2bb92b4"
      },
      "source": [
        "thresh = 5\n",
        "preds_bin = np.array([1 if x < thresh else 0 for x in preds_array])\n",
        "true_bin = np.array([1 if x < thresh else 0 for x in true_array])\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "confusion_matrix(true_bin,preds_bin)"
      ],
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[256,  10],\n",
              "       [ 86,  40]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 231
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-nxX6gz4tKD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "6e266655-e3ce-4969-9497-96266d0ddd7b"
      },
      "source": [
        "print(classification_report(true_bin,preds_bin))"
      ],
      "execution_count": 232,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.96      0.84       266\n",
            "           1       0.80      0.32      0.45       126\n",
            "\n",
            "    accuracy                           0.76       392\n",
            "   macro avg       0.77      0.64      0.65       392\n",
            "weighted avg       0.77      0.76      0.72       392\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p97Ysn3ESkcv",
        "colab_type": "text"
      },
      "source": [
        "# Not bad at all, about as good as RF, and has the potential to predict out of cluster better"
      ]
    }
  ]
}